# ================================================================
# Application Streamlit : Incidence des maladies (C√¥te d'Ivoire, 2012‚Äì2015)
# Fichier unique, pages en onglets, variables/fonctions en fran√ßais,
# commentaires ligne par ligne, pr√™t pour d√©ploiement Streamlit.
# ================================================================

# ------------- Importations (toutes comment√©es) -------------
from pathlib import Path                               # Pour g√©rer les chemins robustement (assets, CSV)
import io                                              # Pour cr√©er des contenus t√©l√©chargeables en m√©moire
import numpy as np                                     # Pour les calculs num√©riques (statistiques, z-score)
import pandas as pd                                    # Pour manipuler les donn√©es tabulaires
import plotly.express as px                            # Pour des graphiques interactifs rapides
import streamlit as st                                 # Pour construire l‚Äôinterface web
from sklearn.model_selection import train_test_split, cross_val_score  # Pour split et validation crois√©e
from sklearn.compose import ColumnTransformer          # Pour appliquer des transformations par type de colonne
from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures  # Encodage/scaling/features
from sklearn.pipeline import Pipeline                  # Pour encha√Æner pr√©traitements + mod√®le
from sklearn.linear_model import LinearRegression      # Mod√®le de r√©gression lin√©aire
from sklearn.ensemble import RandomForestRegressor     # Mod√®le de r√©gression par for√™ts al√©atoires
from sklearn.neighbors import KNeighborsRegressor      # Mod√®le KNN r√©gression
from sklearn.neural_network import MLPRegressor       # R√©seau de neurones (petit MLP scikit-learn)
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error  # M√©triques de r√©gression
from pandas.api import types as ptypes                 # Pour d√©tecter proprement les dtypes pandas

# ------------- Pr√©f√©rences pandas (√©viter warnings verbeux) -------------
pd.set_option("future.no_silent_downcasting", True)    # D√©clarons l‚Äôoption futur pour √©viter les downcasts silencieux

# ------------- R√©solution des chemins d‚Äôassets (image, CSV) -------------
def chemin_depuis_app(relatif: str) -> Path:
    """Retourner un chemin absolu √† partir du dossier contenant ce app.py."""
    return (Path(__file__).parent / relatif).resolve()  # Construisons un chemin absolu robuste

def chemin_image_page() -> str | None:
    """Chercher l‚Äôic√¥ne d‚Äôonglet dans assets/, sinon retourner None."""
    p = chemin_depuis_app("assets/moustique_tigre.jpg")  # Chargeons le fichier assets/moustique_tigre.jpg pour l‚Äôic√¥ne
    return str(p) if p.exists() else None               # Renvoyons le chemin si trouv√©e, sinon None

# ------------- Configuration Streamlit -------------
st.set_page_config(                                     # Configurons la page pour un rendu large et propre
    page_title="Incidence maladies CI (2012‚Äì2015)",     # Titre d‚Äôonglet navigateur
    page_icon=(chemin_image_page() or "ü¶ü"),            # Ic√¥ne: image si dispo, sinon emoji
    layout="wide"                                       # Mise en page pleine largeur
)

# ------------- Style l√©ger (CSS) -------------
st.markdown("""
<style>
.block { background:#fff; padding:16px; border-radius:12px; box-shadow:0 2px 10px rgba(0,0,0,0.06); }
h2, h3 { color:#0D1D2C; }
[data-testid="stDataFrame"] { border:1px solid #eee; border-radius:8px; }
</style>
""", unsafe_allow_html=True)

# ================================================================
# Fonctions utilitaires (en fran√ßais, *ce qui est fait et pourquoi*)
# ================================================================

@st.cache_data(show_spinner=True, ttl=3600)
def charger_donnees_csv(chemin_csv: str) -> pd.DataFrame:
    """Chargeons le fichier CSV pour alimenter l‚Äôapplication sans relire le disque √† chaque interaction."""
    df = pd.read_csv(chemin_csv)                        # Lisons le CSV fourni (Incidence.csv)
    return df                                           # Renvoyons le DataFrame brut

def normaliser_noms_colonnes(df: pd.DataFrame) -> pd.DataFrame:
    """Harmonisons les libell√©s de colonnes pour g√©rer les variantes et coder de fa√ßon stable."""
    donnees = df.copy()                                 # Copions pour √©viter les effets de bord
    mapping = {                                         # D√©finissons un mapping des variantes -> noms standard
        "ANNEE": "annee",
        "REGIONS / DISTRICTS": "regions_districts",
        "REGIONS/DISTRICTS": "regions_districts",
        "VILLES / COMMUNES": "villes_communes",
        "VILLES/COMMUNES": "villes_communes",
        "MALADIE": "maladie",
        "INCIDENCE SUR LA POPULATION GENERALE (%)": "incidence_population_pct",
        "INCIDENCE_SUR_LA_POPULATION_GENERALE_(%)": "incidence_population_pct",
    }
    renoms = {c: mapping[c] for c in donnees.columns if c in mapping}  # Conservons uniquement les cl√©s pr√©sentes
    donnees = donnees.rename(columns=renoms)           # Appliquons le renommage pr√©sent
    donnees.columns = [c.strip().lower().replace(" ", "_") for c in donnees.columns]  # Uniformisons le reste
    return donnees                                     # Renvoyons un sch√©ma de colonnes stable

def typer_colonnes(donnees: pd.DataFrame) -> pd.DataFrame:
    """Typage contr√¥l√© : ann√©e en entier tol√©rant NA, incidence en float, cat√©gories en string (pandas)."""
    df = donnees.copy()                                # Copions le DF d‚Äôentr√©e
    if "annee" in df.columns:                          # Si la colonne annee existe
        df["annee"] = pd.to_numeric(df["annee"], errors="coerce").astype("Int64")  # Convertissons en entier nullable
    if "incidence_population_pct" in df.columns:       # Si la colonne incidence existe
        df["incidence_population_pct"] = pd.to_numeric(df["incidence_population_pct"], errors="coerce")  # En float
    for c in ["regions_districts", "villes_communes", "maladie"]:  # Pour chaque colonne cat√©gorielle
        if c in df.columns:
            df[c] = df[c].astype("string")             # For√ßons un type string propre
    return df                                          # Renvoyons le DF typ√©

def statistiques_rapides(df: pd.DataFrame) -> pd.DataFrame:
    """Calculons les statistiques descriptives pour les colonnes num√©riques (survol rapide)."""
    return df.select_dtypes(include=[np.number]).describe().T  # Utilisons describe() puis transposons pour lisibilit√©

def valeurs_manquantes(df: pd.DataFrame) -> pd.DataFrame:
    """Comptons les valeurs manquantes par colonne pour cibler le nettoyage."""
    na = df.isna().sum().sort_values(ascending=False)  # Comptons les NA
    return pd.DataFrame({"colonne": na.index, "manquants": na.values})  # Renvoyons un tableau clair

def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoyons : doublons supprim√©s, imputations (m√©diane en num√©rique, mode en cat√©goriel) pour fiabiliser l‚ÄôEDA."""
    donnees = df.copy()                                # Copions
    donnees = donnees.drop_duplicates()                # Supprimons les doublons ligne √† ligne

    cols_num = donnees.select_dtypes(include=[np.number, "Int64", "Float64"]).columns.tolist()  # Num√©riques
    cols_cat = [c for c in donnees.columns if c not in cols_num]  # Cat√©gorielles = compl√©ment

    for c in cols_num:                                 # Parcourons les num√©riques
        if donnees[c].isna().any():                    # Si NA pr√©sents
            donnees[c] = donnees[c].fillna(donnees[c].median())  # Rempla√ßons par la m√©diane (robuste)

    for c in cols_cat:                                 # Parcourons les cat√©gorielles
        if donnees[c].isna().any():                    # Si NA pr√©sents
            mode = donnees[c].mode(dropna=True)        # Calculons la modalit√© la plus fr√©quente
            if len(mode) > 0:
                donnees[c] = donnees[c].fillna(mode.iloc[0])  # Rempla√ßons par ce mode

    return donnees                                     # Renvoyons la version nettoy√©e

def rendre_arrow_compatible(df: pd.DataFrame) -> pd.DataFrame:
    """Rendons le DF compatible Arrow/Streamlit: on convertit Int64 nullable et object h√©t√©rog√®ne pour √©viter les correctifs auto."""
    dfa = df.copy()                                    # Copions le DF
    for col in dfa.columns:                            # Parcourons chaque colonne
        dtype = dfa[col].dtype                         # R√©cup√©rons le dtype
        # Entiers "nullable" (Int64, Int32, ‚Ä¶) ‚Üí float64 s‚Äôil y a NA (pr√©serve NA), sinon int64 pur
        if ptypes.is_extension_array_dtype(dtype) and str(dtype).startswith("Int"):
            if dfa[col].isna().any():
                dfa[col] = dfa[col].astype("float64")  # Passons en float64 pour g√©rer NA proprement
            else:
                dfa[col] = dfa[col].astype("int64")    # Sinon int64 natif
        # Objets h√©t√©rog√®nes ‚Üí tentons num√©rique, sinon string explicite
        elif dtype == "object":
            conv = pd.to_numeric(dfa[col], errors="ignore")  # Tentons conversion
            dfa[col] = conv if conv.dtype != "object" else dfa[col].astype("string")  # For√ßons string si n√©cessaire
    return dfa                                          # Renvoyons un DF Arrow-safe

def detecter_valeurs_aberrantes(df: pd.DataFrame, z: float = 3.0) -> pd.DataFrame:
    """D√©tectons des lignes pr√©sentant au moins un z-score > z sur les variables num√©riques (rep√©rage d‚Äôanomalies)."""
    dnum = df.select_dtypes(include=[np.number])       # Conservons uniquement le num√©rique
    if dnum.empty:                                     # Si rien de num√©rique
        return df.head(0)                              # Renvoyons un DF vide
    zscores = (dnum - dnum.mean()) / dnum.std(ddof=0)  # Calculons les z-scores
    masque_out = (zscores.abs() > z).any(axis=1)       # Marquons les lignes aberrantes
    return df.loc[masque_out]                          # Renvoyons ces lignes

def telecharger_csv(df: pd.DataFrame) -> bytes:
    """Convertissons un DataFrame en CSV (bytes) pour t√©l√©chargement via st.download_button sans √©crire sur disque."""
    tampon = io.StringIO()                             # Ouvrons un tampon texte en m√©moire
    df.to_csv(tampon, index=False)                     # √âcrivons le CSV
    return tampon.getvalue().encode("utf-8")           # Retournons les octets UTF-8

# ================================================================
# Chargement & pr√©paration (fait une seule fois gr√¢ce au cache)
# ================================================================

# Chargeons le CSV source (nom impos√© : Incidence.csv √† la racine du d√©p√¥t)
donnees_brutes = charger_donnees_csv(chemin_depuis_app("Incidence.csv"))  # Chargeons le jeu brut
donnees = normaliser_noms_colonnes(donnees_brutes)                        # Normalisons les colonnes
donnees = typer_colonnes(donnees)                                         # Appliquons un typage coh√©rent
donnees_nettoyees = nettoyer_donnees(donnees)                             # Nettoyons le dataset

# Conservons le DF nettoy√© en session pour r√©utiliser sans recalcul
if "donnees_nettoyees" not in st.session_state:                           # Si pas encore pr√©sent
    st.session_state["donnees_nettoyees"] = donnees_nettoyees             # Stockons en session

# ================================================================
# Navigation horizontale par onglets
# ================================================================
onglets = st.tabs([
    "üè† Accueil", "üìí Informations", "üõ† Exploration", "üßπ Pr√©paration",
    "üîç Visualisations", "üëÄ Explorateur", "„ÄΩÔ∏è Mod√©lisation", "‚óª Pr√©diction", "üõñ Source"
])

# =========================
# üè† ACCUEIL
# =========================
with onglets[0]:
    st.title("Incidence des maladies en C√¥te d‚ÄôIvoire (2012‚Äì2015)")      # Posons un titre clair
    col1, col2 = st.columns([1, 2], gap="large")                          # Deux colonnes pour une intro agr√©able
    with col1:
        p_img = chemin_depuis_app("assets/moustique_tigre.jpg")           # Chargeons l‚Äôimage d‚Äôillustration depuis assets/
        if p_img.exists():
            st.image(str(p_img), use_column_width=True,
                     caption="Aedes albopictus (moustique tigre)")        # Affichons l‚Äôimage si disponible
        else:
            st.markdown("### ü¶ü")                                         # Fallback visuel l√©ger si absente
    with col2:
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Objectif de l‚Äôapplication</h3>
        Explorer, visualiser et mod√©liser l‚Äôincidence de maladies en C√¥te d‚ÄôIvoire (2012‚Äì2015) : 
        graphiques interactifs, explorateur visuel (Pygwalker) et mod√®les pr√©dictifs (R√©gression, RF, KNN, MLP).
        </div>""", unsafe_allow_html=True)
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Probl√®me adress√©</h3>
        Transformer des donn√©es brutes de sant√© publique en <b>indicateurs actionnables</b> et en <b>pr√©dictions</b> 
        pour aider √† prioriser les zones et pathologies.
        </div>""", unsafe_allow_html=True)
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>R√©sultats attendus</h3>
        Un outil unique pour : (1) analyser les tendances, (2) comparer les r√©gions, 
        (3) pr√©dire l‚Äôincidence selon ann√©e/r√©gion/ville/maladie.
        </div>""", unsafe_allow_html=True)

# =========================
# üìí INFORMATIONS
# =========================
with onglets[1]:
    st.header("Informations sur les donn√©es")                             # Annon√ßons la section
    st.write("**Aper√ßu des premi√®res lignes (jeu d‚Äôorigine)**")           # Pr√©sentons l‚Äôaper√ßu
    st.dataframe(                                                         # Affichons un √©chantillon Arrow-safe
        rendre_arrow_compatible(donnees_brutes.head()),
        use_container_width=True
    )
    st.write("**Libell√©s de colonnes normalis√©s (utilis√©s en interne)**") # Expliquons les noms internes
    st.json({
        "annee": "Ann√©e d‚Äôobservation (2012‚Äì2015)",
        "regions_districts": "R√©gion ou district sanitaire",
        "villes_communes": "Ville ou commune",
        "maladie": "Type de pathologie",
        "incidence_population_pct": "Incidence sur la population g√©n√©rale (en %)"
    })

# =========================
# üõ† EXPLORATION (tables empil√©es verticalement)
# =========================
with onglets[2]:
    st.header("Exploration des donn√©es")                                   # Titre de section
    st.subheader("Dimensions & dtypes")                                    # Sous-titre
    st.write(f"**Nombre de lignes** : {donnees_nettoyees.shape[0]}")       # Indiquons le nb de lignes
    st.write(f"**Nombre de colonnes** : {donnees_nettoyees.shape[1]}")     # Indiquons le nb de colonnes
    st.dataframe(                                                          # Dtypes lisibles
        rendre_arrow_compatible(donnees_nettoyees.dtypes.to_frame("dtype")),
        use_container_width=True
    )

    st.subheader("Valeurs manquantes par colonne")                         # Sous-titre
    st.dataframe(
        rendre_arrow_compatible(valeurs_manquantes(donnees_nettoyees)),
        use_container_width=True
    )

    st.subheader("Statistiques descriptives (num√©riques)")                 # Sous-titre
    st.dataframe(
        rendre_arrow_compatible(statistiques_rapides(donnees_nettoyees)),
        use_container_width=True
    )

    st.subheader("Valeurs aberrantes potentielles (z-score > 3)")          # Sous-titre
    outliers = detecter_valeurs_aberrantes(donnees_nettoyees)              # Rep√©rons les anomalies
    if outliers.empty:                                                     # Si rien d‚Äôaberrant
        st.info("Aucune ligne ne d√©passe le seuil de z-score s√©lectionn√© (3.0).")
    else:
        st.dataframe(rendre_arrow_compatible(outliers), use_container_width=True)

# =========================
# üßπ PR√âPARATION (export)
# =========================
with onglets[3]:
    st.header("Pr√©paration et export des donn√©es")                         # Titre de section
    st.write("**Aper√ßu apr√®s nettoyage (doublons supprim√©s, NA imput√©s)**")
    st.dataframe(
        rendre_arrow_compatible(donnees_nettoyees.head(20)),
        use_container_width=True
    )
    st.download_button(                                                    # Proposons un export CSV
        label="üì• T√©l√©charger les donn√©es nettoy√©es (CSV)",
        data=telecharger_csv(donnees_nettoyees),
        file_name="incidence_nettoyee.csv",
        mime="text/csv"
    )

# =========================
# üîç VISUALISATIONS (filtres + 3 graphiques)
# =========================
with onglets[4]:
    st.header("Visualisations interactives")                               # Titre de section
    dfv = donnees_nettoyees                                                # Alias local

    colf1, colf2, colf3 = st.columns(3)                                    # 3 filtres c√¥te √† c√¥te
    with colf1:
        maladies_dispo = sorted(dfv["maladie"].dropna().unique().tolist())  # Liste des maladies
        choix_maladie = st.selectbox("Choisir une maladie", maladies_dispo, index=0)
    with colf2:
        annees_dispo = sorted(dfv["annee"].dropna().astype(int).unique().tolist())  # Liste des ann√©es
        choix_annees = st.multiselect("Filtrer par ann√©e", annees_dispo, default=annees_dispo)
    with colf3:
        regions_dispo = ["(Toutes)"] + sorted(dfv["regions_districts"].dropna().unique().tolist())  # R√©gions
        choix_region = st.selectbox("Filtrer par r√©gion/district", regions_dispo, index=0)

    dff = dfv[dfv["maladie"] == choix_maladie]                             # Appliquons filtre maladie
    dff = dff[dff["annee"].isin(choix_annees)]                             # Filtrons les ann√©es
    if choix_region != "(Toutes)":                                         # Si r√©gion choisie
        dff = dff[dff["regions_districts"] == choix_region]                # Filtrons la r√©gion

    st.subheader("√âvolution de l‚Äôincidence (%) dans le temps")             # Graphique 1
    if len(dff) == 0:
        st.warning("Aucune donn√©e pour ce filtre.")
    else:
        evol = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
        fig1 = px.line(evol, x="annee", y="incidence_population_pct",
                       markers=True,
                       labels={"annee": "Ann√©e", "incidence_population_pct": "Incidence (%)"},
                       title=f"√âvolution ‚Äî {choix_maladie}")
        st.plotly_chart(fig1, use_container_width=True)

    st.subheader("Comparaison des r√©gions/districts (moyenne)")            # Graphique 2
    comp = dfv[dfv["maladie"] == choix_maladie]
    comp = comp[comp["annee"].isin(choix_annees)]
    comp = comp.groupby("regions_districts", dropna=True)["incidence_population_pct"].mean().reset_index()
    comp = comp.sort_values("incidence_population_pct", ascending=False).head(20)
    fig2 = px.bar(comp, x="regions_districts", y="incidence_population_pct",
                  labels={"regions_districts": "R√©gion/District", "incidence_population_pct": "Incidence (%)"},
                  title=f"Top r√©gions ‚Äî {choix_maladie} (moyenne {min(choix_annees)}‚Äì{max(choix_annees)})")
    fig2.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig2, use_container_width=True)

    st.subheader("R√©partition par ann√©e (moyenne)")                        # Graphique 3
    rep = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
    fig3 = px.pie(rep, names="annee", values="incidence_population_pct", title="Part relative moyenne par ann√©e", hole=0.35)
    st.plotly_chart(fig3, use_container_width=True)

# =========================
# üëÄ EXPLORATEUR (Pygwalker, stable)
# =========================
with onglets[5]:
    st.header("Explorateur visuel libre (Pygwalker)")                      # Titre de section
    st.info("Astuce : glissez-d√©posez les champs √† gauche pour cr√©er vos vues interactives.")
    try:
        # Importons le renderer officiel Streamlit (plus stable qu‚Äôun HTML brut)
        from pygwalker.api.streamlit import StreamlitRenderer             # Importons l‚ÄôAPI int√©gr√©e

        @st.cache_resource(show_spinner=False)
        def obtenir_renderer(df: pd.DataFrame):
            """Construisons un renderer Pygwalker mis en cache pour √©viter des re-instanciations co√ªteuses."""
            return StreamlitRenderer(df, spec_io_mode="rw")               # Autorisons lecture/√©criture de la spec localement

        renderer = obtenir_renderer(donnees_nettoyees)                    # Instancions le renderer (cach√©)
        renderer.explorer(height=900, scrolling=True, default_tab="vis")  # Ouvrons l‚Äôexplorateur

    except Exception as e:
        st.error("Pygwalker n‚Äôa pas pu √™tre charg√©. V√©rifiez l‚Äôenvironnement et la version install√©e.")
        st.exception(e)                                                   # Montrons l‚Äôexception pour diagnostic

# =========================
# „ÄΩÔ∏è MOD√âLISATION (entra√Ænement √† la demande)
# =========================
with onglets[6]:
    st.header("Mod√©lisation supervis√©e (r√©gression)")                     # Titre de section
    colp1, colp2, colp3 = st.columns(3)                                   # Param√®tres utilisateur
    with colp1:
        type_modele = st.selectbox(
            "Choisir un mod√®le",
            ["R√©gression lin√©aire", "R√©gression polynomiale", "For√™t al√©atoire",
             "KNN r√©gression", "R√©seau de neurones (ANN)"]
        )
    with colp2:
        taille_test = st.slider("Taille test (%)", 10, 40, 20, step=5)    # Taille test
    with colp3:
        graine = st.number_input("Graine al√©atoire", value=42, step=1)    # Graine

    # Pr√©parons X/y (caract√©ristiques et cible)
    X = donnees_nettoyees[["annee", "regions_districts", "villes_communes", "maladie"]]
    y = donnees_nettoyees["incidence_population_pct"]

    colonnes_numeriques = ["annee"]                                       # Num√©rique
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]  # Cat√©gorielles

    preprocesseur = ColumnTransformer(                                     # Pr√©traitement par type
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles)
        ]
    )

    # D√©coupons apprentissage/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=taille_test/100.0, random_state=int(graine)
    )

    # Construisons le pipeline selon le choix
    if type_modele == "R√©gression lin√©aire":
        pipeline = Pipeline([("prep", preprocesseur), ("mod", LinearRegression())])

    elif type_modele == "R√©gression polynomiale":
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("poly", PolynomialFeatures(degree=2, include_bias=False)),
            ("mod", LinearRegression())
        ])

    elif type_modele == "For√™t al√©atoire":
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("mod", RandomForestRegressor(n_estimators=300, random_state=int(graine)))
        ])

    elif type_modele == "KNN r√©gression":
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("mod", KNeighborsRegressor(n_neighbors=7))
        ])

    else:  # R√©seau de neurones
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("mod", MLPRegressor(hidden_layer_sizes=(128, 64),
                                 activation="relu", solver="adam",
                                 max_iter=1000, random_state=int(graine)))
        ])

    # Bouton explicite d‚Äôentra√Ænement (√©vite de r√©entra√Æner √† chaque changement mineur)
    if st.button("üîÅ Entra√Æner / R√©entra√Æner le mod√®le"):
        pipeline.fit(X_train, y_train)                                     # Entra√Ænons le pipeline
        y_pred = pipeline.predict(X_test)                                  # Pr√©dictions test
        r2 = r2_score(y_test, y_pred)                                      # R¬≤
        mae = mean_absolute_error(y_test, y_pred)                          # MAE
        rmse = mean_squared_error(y_test, y_pred, squared=False)           # RMSE (API r√©cente)

        c1, c2, c3 = st.columns(3)                                         # Montrons les m√©triques
        c1.metric("R¬≤", f"{r2:.3f}")
        c2.metric("MAE", f"{mae:.3f}")
        c3.metric("RMSE", f"{rmse:.3f}")

        with st.expander("Voir la validation crois√©e (5 plis)"):
            scores = cross_val_score(pipeline, X, y, cv=5, scoring="r2")
            st.write("Scores R¬≤ par pli :", [f"{s:.3f}" for s in scores])
            st.write("R¬≤ moyen :", f"{np.mean(scores):.3f} ¬± {np.std(scores):.3f}")

        st.session_state["pipeline_modele"] = pipeline                     # Stockons le mod√®le en session
        st.success("‚úÖ Mod√®le entra√Æn√© et stock√© pour l‚Äôonglet ‚óª Pr√©diction.")

    else:
        st.info("Cliquez sur **Entra√Æner / R√©entra√Æner le mod√®le** pour calculer les m√©triques et activer la pr√©diction.")

# =========================
# ‚óª PR√âDICTION
# =========================
with onglets[7]:
    st.header("Pr√©dire l‚Äôincidence (%) selon vos s√©lections")             # Titre de section
    if "pipeline_modele" not in st.session_state:                         # V√©rifions qu‚Äôun mod√®le existe
        st.warning("Aucun mod√®le disponible. Allez dans **„ÄΩÔ∏è Mod√©lisation** puis entra√Ænez le mod√®le.")
    else:
        pipe = st.session_state["pipeline_modele"]                        # R√©cup√©rons le pipeline

        col1, col2, col3, col4 = st.columns(4)                            # Quatre crit√®res d‚Äôentr√©e
        with col1:
            annee_sel = st.selectbox("Ann√©e", sorted(donnees_nettoyees["annee"].dropna().astype(int).unique()))
        with col2:
            region_sel = st.selectbox("R√©gion/District", sorted(donnees_nettoyees["regions_districts"].dropna().unique()))
        with col3:
            ville_sel = st.selectbox("Ville/Commune", sorted(donnees_nettoyees["villes_communes"].dropna().unique()))
        with col4:
            maladie_sel = st.selectbox("Maladie", sorted(donnees_nettoyees["maladie"].dropna().unique()))

        # Construisons une observation √† une ligne avec les m√™mes noms de colonnes que X
        saisie = pd.DataFrame({
            "annee": [int(annee_sel)],
            "regions_districts": [region_sel],
            "villes_communes": [ville_sel],
            "maladie": [maladie_sel]
        })

        if st.button("üîÆ Lancer la pr√©diction"):
            y_hat = float(pipe.predict(saisie)[0])                         # Calculons la pr√©diction (float)
            st.success(f"Incidence attendue : **{y_hat:.2f} %**")          # Affichons le r√©sultat

            # Calculons en rep√®re la moyenne historique locale si disponible
            cond = (
                (donnees_nettoyees["annee"] == int(annee_sel)) &
                (donnees_nettoyees["regions_districts"] == region_sel) &
                (donnees_nettoyees["villes_communes"] == ville_sel) &
                (donnees_nettoyees["maladie"] == maladie_sel)
            )
            ref_local = donnees_nettoyees.loc[cond, "incidence_population_pct"].mean()
            if not np.isnan(ref_local):
                st.info(f"Moyenne observ√©e (historique, m√™mes filtres) : **{ref_local:.2f} %**")

# =========================
# üõñ SOURCE
# =========================
with onglets[8]:
    st.header("Origine des donn√©es")
    st.markdown("""
    - **Source ouverte** : *Incidences de maladies sur la population de 2012 √† 2015*  
    - **Lien** : https://data.gouv.ci/datasets/incidence-de-maladies-sur-la-population-de-2012-a-2015
    """)
    st.caption("Placez **Incidence.csv** √† la racine et l‚Äôimage sous **assets/moustique_tigre.jpg**.")
