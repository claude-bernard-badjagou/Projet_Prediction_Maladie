
# Application Streamlit : Incidence des maladies (C√¥te d'Ivoire, 2012-2015)

# -------- Importations de packages--------
import streamlit as st                     # Importons Streamlit pour construire l'application web interactive
import pandas as pd                        # Importons pandas pour charger et manipuler les donn√©es tabulaires
import numpy as np                         # Importons numpy pour quelques op√©rations num√©riques
import plotly.express as px                # Importons Plotly Express pour cr√©er des visualisations interactives
import plotly.graph_objects as go          # Importons Graph Objects pour des graphiques personnalis√©s
from io import StringIO                    # Importons StringIO pour g√©n√©rer un CSV t√©l√©chargeable en m√©moire
from sklearn.model_selection import train_test_split, cross_val_score # Importons les outils de d√©coupage/cross-val
from sklearn.compose import ColumnTransformer               # Importons ColumnTransformer pour traiter colonnes h√©t√©rog√®nes
from sklearn.preprocessing import OneHotEncoder, StandardScaler # Importons encodeur cat√©goriel et standardisation num√©rique
from sklearn.pipeline import Pipeline                        # Importons Pipeline pour cha√Æner pr√©traitements + mod√®le
from sklearn.linear_model import LinearRegression            # Importons R√©gression lin√©aire
from sklearn.preprocessing import PolynomialFeatures         # Importons g√©n√©rateur de caract√©ristiques polynomiales
from sklearn.ensemble import RandomForestRegressor           # Importons For√™t al√©atoire pour la r√©gression
from sklearn.neighbors import KNeighborsRegressor            # Importons KNN r√©gression
from sklearn.neural_network import MLPRegressor             # Importons Perceptron multi-couches (ANN l√©ger, sans TF)
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error  # Importons les m√©triques de r√©gression
import streamlit.components.v1 as components

# -------- Configuration globale de la page --------
st.set_page_config(                             # Configurons la page Streamlit pour un rendu propre
    page_title="Incidence maladies CI (2012-2015)",  # D√©finissons le titre de l‚Äôonglet navigateur
    page_icon="moustique_tigre.jpg",                 # D√©finissons l‚Äôic√¥ne de page (image partag√©e)
    layout="wide"                                    # Passons en mode large pour mieux exploiter l‚Äô√©cran
)

# -------- Styles CSS l√©gers pour homog√©n√©iser l'UI --------
st.markdown("""                                          
<style>
/* Donnons un l√©ger arrondi et des ombres aux blocs */
.block { background: #ffffff; padding: 16px; border-radius: 12px; 
         box-shadow: 0 2px 10px rgba(0,0,0,0.06); }
/* Mettons en valeur les titres secondaires */
h2, h3 { color: #0D1D2C; }
/* All√©geons l‚Äôapparence des DataFrames */
[data-testid="stDataFrame"] { border: 1px solid #eee; border-radius: 8px; }
</style>
""", unsafe_allow_html=True)

# --------- Fonctions utilitaires (toutes en fran√ßais + commentaires ligne par ligne) ---------

@st.cache_data(show_spinner=True)
def charger_donnees_csv(chemin: str) -> pd.DataFrame:
    """Chargeons le fichier CSV pour obtenir le jeu de donn√©es source."""
    # Chargeons le fichier CSV pour alimenter toutes les pages de l'application
    df = pd.read_csv(chemin)  # Lecture simple du fichier CSV "Incidence.csv" fourni dans les ressources
    return df                  # Renvoyons le DataFrame charg√©

def normaliser_noms_colonnes(df: pd.DataFrame) -> pd.DataFrame:
    """Harmonisons les libell√©s de colonnes pour un code robuste, quelles que soient les variantes d'intitul√©s."""
    # Copions le DataFrame pour √©viter les effets de bord
    donnees = df.copy()  # Copions le DataFrame d‚Äôentr√©e pour travailler en s√©curit√©

    # Cr√©ons une table de correspondance des libell√©s h√©t√©rog√®nes vers des noms normalis√©s (sans espaces/accents)
    # Nous couvrons les deux variantes vues dans tes fichiers : avec slash/espaces et avec underscore.
    mapping = {
        "ANNEE": "annee",
        "REGIONS / DISTRICTS": "regions_districts",
        "REGIONS/DISTRICTS": "regions_districts",
        "VILLES / COMMUNES": "villes_communes",
        "VILLES/COMMUNES": "villes_communes",
        "MALADIE": "maladie",
        "INCIDENCE SUR LA POPULATION GENERALE (%)": "incidence_population_pct",
        "INCIDENCE_SUR_LA_POPULATION_GENERALE_(%)": "incidence_population_pct",
    }

    # Renommons les colonnes existantes si elles figurent dans le mapping
    colonnes_renommees = {c: mapping[c] for c in donnees.columns if c in mapping}  # Pr√©parons le dict des colonnes pr√©sentes
    donnees = donnees.rename(columns=colonnes_renommees)  # Appliquons le renommage

    # Pour plus de robustesse, normalisons tout le reste (minuscules + rempla√ßons espaces par underscore)
    donnees.columns = [c.strip().lower().replace(" ", "_") for c in donnees.columns]  # Nettoyons tous les noms de colonnes
    return donnees  # Renvoyons le DataFrame aux noms standardis√©s

def typer_colonnes(donnees: pd.DataFrame) -> pd.DataFrame:
    """Typage : convertissons ann√©e en entier, incidence en float, autres en str pour des traitements coh√©rents."""
    df = donnees.copy()                                   # Copions le DataFrame
    if "annee" in df.columns:                             # V√©rifions la pr√©sence de la colonne annee
        df["annee"] = pd.to_numeric(df["annee"], errors="coerce").astype("Int64")  # Convertissons en entier tol√©rant NA
    if "incidence_population_pct" in df.columns:          # V√©rifions la pr√©sence de la colonne d‚Äôincidence
        df["incidence_population_pct"] = pd.to_numeric(df["incidence_population_pct"], errors="coerce")  # Convertissons en float
    # For√ßons les colonnes cat√©gorielles en string pour √©viter les surprises plus tard
    for col in ["regions_districts", "villes_communes", "maladie"]:
        if col in df.columns:
            df[col] = df[col].astype("string")            # Convertissons en cha√Ænes (type pandas string)
    return df                                             # Renvoyons le DataFrame typ√©

def statistiques_rapides(df: pd.DataFrame) -> pd.DataFrame:
    """Produisons un tableau synth√©tique des statistiques descriptives num√©riques pour survol rapide."""
    # Utilisons describe() pour obtenir n, moyenne, std, min, max, quartiles sur les colonnes num√©riques
    stats = df.select_dtypes(include=[np.number]).describe().T  # Calculons les statistiques et transposons pour lisibilit√©
    return stats                                           # Renvoyons le tableau de stats

def valeurs_manquantes(df: pd.DataFrame) -> pd.DataFrame:
    """Comptons les valeurs manquantes par colonne pour cibler le nettoyage."""
    # Sommons les NA par colonne et trions par d√©croissant
    na = df.isna().sum().sort_values(ascending=False)     # Comptons les NA par colonne
    return pd.DataFrame({"colonne": na.index, "manquants": na.values})  # Renvoyons un DataFrame propre

def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoyons : supprimons les doublons, imputons les NA (mode sur cat√©goriel, m√©diane sur num√©rique)."""
    donnees = df.copy()                                    # Copions pour pr√©server l‚Äôoriginal
    donnees = donnees.drop_duplicates()                    # Supprimons les √©ventuelles lignes dupliqu√©es

    # S√©parons colonnes num√©riques et cat√©gorielles
    cols_num = donnees.select_dtypes(include=[np.number]).columns.tolist()  # Rep√©rons les colonnes num√©riques
    cols_cat = [c for c in donnees.columns if c not in cols_num]            # Les autres seront trait√©es comme cat√©gorielles

    # Imputons les valeurs manquantes num√©riques par la m√©diane (robuste aux outliers)
    for c in cols_num:
        if donnees[c].isna().any():                        # Si la colonne contient des NA
            donnees[c] = donnees[c].fillna(donnees[c].median())  # Rempla√ßons par la m√©diane

    # Imputons les valeurs manquantes cat√©gorielles par le mode (valeur la plus fr√©quente)
    for c in cols_cat:
        if donnees[c].isna().any():                        # Si la colonne contient des NA
            mode = donnees[c].mode(dropna=True)            # Calculons la modalit√© dominante
            if len(mode) > 0:                              # V√©rifions que le mode existe
                donnees[c] = donnees[c].fillna(mode.iloc[0])  # Rempla√ßons par cette modalit√©

    return donnees                                         # Renvoyons le DataFrame nettoy√©

def detecter_valeurs_aberrantes(df: pd.DataFrame, z=3.0) -> pd.DataFrame:
    """D√©tectons les valeurs aberrantes (z-score > seuil) pour les colonnes num√©riques."""
    # S√©lectionnons uniquement les colonnes num√©riques
    dnum = df.select_dtypes(include=[np.number])           # Extrayons les colonnes num√©riques
    # Calculons le z-score absolu et marquons les lignes contenant au moins un d√©passement
    zscores = (dnum - dnum.mean()) / dnum.std(ddof=0)      # Calculons les z-scores (√©cart-type population)
    masque_out = (zscores.abs() > z).any(axis=1)           # Identifions les lignes avec au moins un z-score > seuil
    return df.loc[masque_out]                              # Renvoyons uniquement les lignes suspectes

def telecharger_csv(df: pd.DataFrame) -> bytes:
    """Pr√©parons un CSV t√©l√©chargeable (en m√©moire) pour r√©cup√©rer les donn√©es nettoy√©es."""
    buffer = StringIO()                                    # Ouvrons un tampon m√©moire texte
    df.to_csv(buffer, index=False)                         # √âcrivons le CSV dans le tampon
    return buffer.getvalue().encode("utf-8")               # Renvoyons les octets encod√©s en UTF-8

# --------- Chargement unique & pr√©paration initiale ---------
# Chargeons le fichier 'Incidence.csv' pour alimenter l'int√©gralit√© de l'app, puis normalisons/typons/Nettoyons
donnees_brutes = charger_donnees_csv("Incidence.csv")          # Chargeons le fichier CSV pour obtenir les donn√©es d'origine
donnees = normaliser_noms_colonnes(donnees_brutes)             # Normalisons les libell√©s pour unifier le code
donnees = typer_colonnes(donnees)                              # Typage coh√©rent (entiers, float, string)
donnees_nettoyees = nettoyer_donnees(donnees)                  # Appliquons un nettoyage simple et robuste

# Stockons dans la session pour r√©utiliser partout sans rechargement
if "donnees_nettoyees" not in st.session_state:                # V√©rifions si la session contient d√©j√† les donn√©es
    st.session_state["donnees_nettoyees"] = donnees_nettoyees  # D√©posons les donn√©es nettoy√©es dans la session

# --------- Barre de navigation horizontale (onglets) ---------
onglets = st.tabs([                                           # Cr√©ons des onglets pour une navigation horizontale claire
    "üè† Accueil", "üìí Informations", "üõ† Exploration", "üßπ Pr√©paration",
    "üîç Visualisations", "üëÄ Explorateur", "„ÄΩÔ∏è Mod√©lisation", "‚óª Pr√©diction", "üõñ Source"
])

# =========================
# üè† ACCUEIL
# =========================
with onglets[0]:
    # Affichons un en-t√™te agr√©able
    st.title("Incidence des maladies en C√¥te d‚ÄôIvoire (2012‚Äì2015)")  # Titre principal de l'application
    col1, col2 = st.columns([1, 2], gap="large")                     # D√©coupons en deux colonnes pour la mise en page

    with col1:
        st.image("moustique_tigre.jpg", use_column_width=True, caption="Aedes albopictus (moustique tigre)")  # Affichons l'image fournie

    with col2:
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Objectif de l‚Äôapplication</h3>
        Cette application interactive permet d‚Äôexplorer, de visualiser et de mod√©liser 
        l‚Äôincidence de plusieurs maladies en C√¥te d‚ÄôIvoire entre 2012 et 2015.
        Elle propose des graphiques interactifs, un explorateur visuel libre (Pygwalker),
        ainsi que plusieurs mod√®les pr√©dictifs (R√©gression, Random Forest, KNN, ANN).
        </div>""", unsafe_allow_html=True)

        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Probl√®me adress√©</h3>
        Comment transformer des donn√©es brutes de sant√© publique en <b>indicateurs actionnables</b> 
        et en <b>pr√©dictions</b> fiables pour aider √† la d√©cision (priorisation des zones et des pathologies) ?
        </div>""", unsafe_allow_html=True)

        st.markdown("""<div class="block" style="text-align:justify">
        <h3>R√©sultats attendus</h3>
        Un <b>outil unique</b> permettant : 
        (1) l‚Äôanalyse rapide des tendances,
        (2) l‚Äôidentification des disparit√©s r√©gionales,
        (3) la pr√©diction de l‚Äôincidence selon ann√©e/r√©gion/ville/maladie.
        </div>""", unsafe_allow_html=True)

# =========================
# üìí INFORMATIONS
# =========================
with onglets[1]:
    st.header("Informations sur les donn√©es")                      # Pla√ßons un en-t√™te clair
    st.write("**Aper√ßu des premi√®res lignes (jeu de donn√©es d‚Äôorigine)**")  # Introduisons l‚Äôaper√ßu
    st.dataframe(donnees_brutes.head(), use_container_width=True)  # Affichons les 5 premi√®res lignes d'origine

    st.write("**Libell√©s de colonnes normalis√©s (utilis√©s en interne)**")   # Expliquons les noms normalis√©s
    st.json({
        "annee": "Ann√©e d‚Äôobservation (2012‚Äì2015)",
        "regions_districts": "R√©gion ou district sanitaire",
        "villes_communes": "Ville ou commune",
        "maladie": "Type de pathologie",
        "incidence_population_pct": "Incidence sur la population g√©n√©rale (en %)"
    })

# =========================
# üõ† EXPLORATION
# =========================
with onglets[2]:
    st.header("Exploration des donn√©es")                               # Titre de section
    colA, colB = st.columns(2)                                         # Cr√©ons 2 colonnes

    with colA:
        st.subheader("Dimensions & dtypes")                             # Sous-titre
        st.write(f"**Nombre de lignes** : {donnees_nettoyees.shape[0]}")# Affichons nb lignes
        st.write(f"**Nombre de colonnes** : {donnees_nettoyees.shape[1]}") # Affichons nb colonnes
        st.write("**Types de donn√©es**")                                # Pr√©sentons les types
        st.dataframe(donnees_nettoyees.dtypes.to_frame("dtype"), use_container_width=True)  # Montrons les dtypes

    with colB:
        st.subheader("Valeurs manquantes")                              # Sous-titre
        st.dataframe(valeurs_manquantes(donnees_nettoyees), use_container_width=True)  # Affichons NA par colonne

    st.subheader("Statistiques descriptives (variables num√©riques)")     # Sous-titre pour stats
    st.dataframe(statistiques_rapides(donnees_nettoyees), use_container_width=True)     # Affichons describe()

    st.subheader("Valeurs aberrantes potentielles (z-score > 3)")       # Sous-titre pour outliers
    outliers = detecter_valeurs_aberrantes(donnees_nettoyees)           # D√©tectons les valeurs anormales
    if outliers.empty:
        st.info("Aucune ligne ne d√©passe le seuil de z-score s√©lectionn√© (3.0).")       # Message si rien
    else:
        st.dataframe(outliers, use_container_width=True)                # Affichons les lignes suspectes

# =========================
# üßπ PR√âPARATION (manipulation)
# =========================
with onglets[3]:
    st.header("Pr√©paration et export des donn√©es")                      # Titre de section

    st.write("**Aper√ßu apr√®s nettoyage (doublons supprim√©s, NA imput√©s)**")  # Introduisons l‚Äôaper√ßu post-nettoyage
    st.dataframe(donnees_nettoyees.head(20), use_container_width=True)       # Affichons 20 lignes pour contr√¥le

    # Bouton de t√©l√©chargement du CSV nettoy√©
    st.download_button(                                                  # Cr√©ons un bouton pour r√©cup√©rer le CSV propre
        label="üì• T√©l√©charger les donn√©es nettoy√©es (CSV)",              # √âtiquette du bouton
        data=telecharger_csv(donnees_nettoyees),                         # Contenu du fichier en m√©moire
        file_name="incidence_nettoyee.csv",                              # Nom du fichier propos√©
        mime="text/csv"                                                  # Type MIME
    )

# =========================
# üîç VISUALISATIONS
# =========================
with onglets[4]:
    st.header("Visualisations interactives")                             # Titre de section
    dfv = donnees_nettoyees                                              # Alias local pour all√©ger l'√©criture

    # ----- Contr√¥les d‚Äôentr√©e pour filtrer les graphiques -----
    colf1, colf2, colf3 = st.columns(3)                                  # Trois filtres c√¥te √† c√¥te

    with colf1:
        maladies_dispo = sorted(dfv["maladie"].dropna().unique().tolist())   # R√©cup√©rons la liste des maladies
        choix_maladie = st.selectbox("Choisir une maladie", maladies_dispo, index=0)  # S√©lecteur maladie

    with colf2:
        annees_dispo = sorted(dfv["annee"].dropna().unique().astype(int).tolist())    # R√©cup√©rons la liste des ann√©es
        choix_annees = st.multiselect("Filtrer par ann√©e", annees_dispo, default=annees_dispo) # S√©lecteur multi ann√©es

    with colf3:
        regions_dispo = ["(Toutes)"] + sorted(dfv["regions_districts"].dropna().unique().tolist()) # Liste des r√©gions
        choix_region = st.selectbox("Filtrer par r√©gion/district", regions_dispo, index=0)         # S√©lecteur r√©gion

    # ----- Appliquons les filtres -----
    dff = dfv[dfv["maladie"] == choix_maladie]                                 # Filtrons sur la maladie s√©lectionn√©e
    dff = dff[dff["annee"].isin(choix_annees)]                                 # Filtrons sur les ann√©es s√©lectionn√©es
    if choix_region != "(Toutes)":                                             # Si une r√©gion pr√©cise est choisie
        dff = dff[dff["regions_districts"] == choix_region]                    # Filtrons sur la r√©gion choisie

    # ----- Graphique 1 : √©volution temporelle -----
    st.subheader("√âvolution de l‚Äôincidence (%) dans le temps")                 # Sous-titre
    if len(dff) == 0:                                                          # Si le filtre est trop restrictif
        st.warning("Aucune donn√©e pour ce filtre.")                            # Avertissons l'utilisateur
    else:
        # Calculons la moyenne par ann√©e pour lisser les valeurs
        evol = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()  # Moyenne par ann√©e
        fig1 = px.line(evol, x="annee", y="incidence_population_pct",
                       markers=True, labels={"annee": "Ann√©e", "incidence_population_pct": "Incidence (%)"},
                       title=f"√âvolution ‚Äî {choix_maladie}")                   # Construisons une courbe avec marqueurs
        st.plotly_chart(fig1, use_container_width=True)                        # Affichons le graphique

    # ----- Graphique 2 : comparaison par r√©gion (moyenne) -----
    st.subheader("Comparaison des r√©gions/districts (moyenne)")               # Sous-titre
    comp = dfv[dfv["maladie"] == choix_maladie]                                # Filtrons sur la maladie
    comp = comp[comp["annee"].isin(choix_annees)]                              # Filtrons sur les ann√©es
    comp = comp.groupby("regions_districts", dropna=True)["incidence_population_pct"].mean().reset_index()  # Moyennes
    comp = comp.sort_values("incidence_population_pct", ascending=False).head(20)  # Gardons les 20 plus √©lev√©es pour lisibilit√©
    fig2 = px.bar(comp, x="regions_districts", y="incidence_population_pct",
                  labels={"regions_districts": "R√©gion/District", "incidence_population_pct": "Incidence (%)"},
                  title=f"Top r√©gions ‚Äî {choix_maladie} (moyenne {min(choix_annees)}‚Äì{max(choix_annees)})") # Barres tri√©es
    fig2.update_layout(xaxis_tickangle=-45)                                    # Penchons les √©tiquettes pour lisibilit√©
    st.plotly_chart(fig2, use_container_width=True)                            # Affichons

    # ----- Graphique 3 : r√©partition par ann√©e (camembert) -----
    st.subheader("R√©partition par ann√©e (moyenne)")                            # Sous-titre
    rep = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()      # Moyenne par ann√©e
    fig3 = px.pie(rep, names="annee", values="incidence_population_pct",
                  title="Part relative moyenne par ann√©e", hole=0.35)          # Camembert en donut
    st.plotly_chart(fig3, use_container_width=True)                            # Affichons

# =========================
# üëÄ EXPLORATEUR (Pygwalker)
# =========================
with onglets[5]:
    st.header("Explorateur visuel libre (Pygwalker)")
    st.info("Astuce : glissez-d√©posez les champs √† gauche pour cr√©er vos vues interactives.")

    try:
        # Chargeons Pygwalker pour g√©n√©rer un studio d‚Äôexploration visuelle embarqu√©
        import pygwalker as pyg

        # Convertissons le DataFrame en interface HTML interactive de Pygwalker
        html = pyg.to_html(donnees_nettoyees)

        # ‚úÖ Appel correct de l‚ÄôAPI Streamlit Components
        components.html(html, height=900, scrolling=True)

    except ModuleNotFoundError:
        st.error("Pygwalker n‚Äôest pas install√©. V√©rifiez qu‚Äôil est bien dans requirements.txt (pygwalker==0.4.8.9).")
    except Exception as e:
        st.error("Pygwalker n‚Äôa pas pu √™tre charg√©. V√©rifiez l‚Äôenvironnement de d√©ploiement.")
        st.exception(e)

# =========================
# „ÄΩÔ∏è MOD√âLISATION
# =========================
with onglets[6]:
    st.header("Mod√©lisation supervis√©e (r√©gression)")                          # Titre de section

    # --------- Param√®tres utilisateur ----------
    colp1, colp2, colp3 = st.columns(3)                                        # Trois colonnes de param√®tres mod√®le
    with colp1:
        type_modele = st.selectbox("Choisir un mod√®le",
                                   ["R√©gression lin√©aire", "R√©gression polynomiale", "For√™t al√©atoire",
                                    "KNN r√©gression", "R√©seau de neurones (ANN)"])  # Choix du mod√®le
    with colp2:
        test_size = st.slider("Taille test (%)", 10, 40, 20, step=5)           # Pourcentage du jeu de test
    with colp3:
        random_state = st.number_input("Graine al√©atoire", value=42, step=1)   # Graine pour reproductibilit√©

    # --------- Pr√©paration X / y ----------
    # Chargeons les caract√©ristiques pour pr√©dire l'incidence (%)
    X = donnees_nettoyees[["annee", "regions_districts", "villes_communes", "maladie"]]  # S√©lectionnons les features
    y = donnees_nettoyees["incidence_population_pct"]                                     # D√©finissons la cible

    # D√©finissons colonnes num√©riques et cat√©gorielles
    colonnes_numeriques = ["annee"]                                                       # Une seule num√©rique
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]          # Trois cat√©gorielles

    # Construisons le pr√©processeur (standardisation + one-hot)
    preprocesseur = ColumnTransformer(                                                    # Cr√©ons un transformateur par type
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),                               # Standardisons les num√©riques
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles)       # Encodons en one-hot les cat√©gorielles
        ]
    )

    # D√©composons les donn√©es en apprentissage/test
    X_train, X_test, y_train, y_test = train_test_split(                                  # Effectuons le split en un appel
        X, y, test_size=test_size/100, random_state=int(random_state)
    )

    # --------- S√©lection/Construction du pipeline mod√®le ----------
    if type_modele == "R√©gression lin√©aire":                                              # Cas 1 : r√©gression lin√©aire
        modele = LinearRegression()                                                       # Instancions le mod√®le simple
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])                   # Chaignons pr√©traitement + mod√®le

    elif type_modele == "R√©gression polynomiale":                                         # Cas 2 : r√©gression polynomiale
        # Ajoutons des termes polynomiaux (sur les variables num√©riques d√©j√† standardis√©es)
        # NB : On applique PolynomialFeatures apr√®s l'encodage via une sous-pipeline pour n‚Äôagir que sur les num.
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("poly", PolynomialFeatures(degree=2, include_bias=False)),                   # Cr√©ons des interactions quadratiques
            ("mod", LinearRegression())                                                   # Finissons par une r√©gression lin√©aire
        ])

    elif type_modele == "For√™t al√©atoire":                                                # Cas 3 : RandomForest Regressor
        modele = RandomForestRegressor(n_estimators=300, random_state=int(random_state))  # Initialisons la for√™t
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])                   # Chaignons avec le pr√©traitement

    elif type_modele == "KNN r√©gression":                                                 # Cas 4 : KNN
        modele = KNeighborsRegressor(n_neighbors=7)                                       # Instancions un KNN (k=7 par d√©faut)
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])                   # Pipeline complet

    else:                                                                                 # Cas 5 : ANN via MLPRegressor
        modele = MLPRegressor(hidden_layer_sizes=(128, 64),                               # R√©seau 2 couches (128, 64)
                              activation="relu", solver="adam",
                              max_iter=1000, random_state=int(random_state))
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])                   # Pipeline complet

    # --------- Entra√Ænement + √âvaluation ----------
    # Entra√Ænons le pipeline sur X_train, y_train
    pipeline.fit(X_train, y_train)                                                        # Apprenons le mod√®le sur le jeu train

    # Pr√©dictions sur X_test
    y_pred = pipeline.predict(X_test)                                                     # Produisons les pr√©dictions de test

    # Calculons les m√©triques
    r2 = r2_score(y_test, y_pred)                                                         # Calculons le R¬≤
    mae = mean_absolute_error(y_test, y_pred)                                             # Erreur absolue moyenne
    rmse = mean_squared_error(y_test, y_pred, squared=False)                              # Racine de l‚Äôerreur quadratique

    colm1, colm2, colm3 = st.columns(3)                                                   # Trois cartes de m√©triques
    colm1.metric("R¬≤", f"{r2:0.3f}")                                                      # Affichons le R¬≤
    colm2.metric("MAE", f"{mae:0.3f}")                                                    # Affichons le MAE
    colm3.metric("RMSE", f"{rmse:0.3f}")                                                  # Affichons le RMSE

    # Cross-validation 5-fold pour robustesse (sur l‚Äôensemble complet)
    with st.expander("Voir la validation crois√©e (5 plis)"):
        scores = cross_val_score(pipeline, X, y, cv=5, scoring="r2")                      # Calculons les R¬≤ en CV
        st.write("Scores R¬≤ par pli :", [f"{s:0.3f}" for s in scores])                    # Affichons les scores par pli
        st.write("R¬≤ moyen :", f"{np.mean(scores):0.3f} ¬± {np.std(scores):0.3f}")        # Moyenne et √©cart-type

    # Mettons le pipeline dans la session pour r√©utilisation dans l‚Äôonglet Pr√©diction
    st.session_state["pipeline_modele"] = pipeline                                        # Stockons le pipeline entra√Æn√©
    st.success("Mod√®le entra√Æn√© et stock√© pour l‚Äôonglet ‚óª Pr√©diction.")                   # Indiquons la disponibilit√©

# =========================
# ‚óª PR√âDICTION
# =========================
with onglets[7]:
    st.header("Pr√©dire l‚Äôincidence (%) selon vos s√©lections")                             # Titre de section

    if "pipeline_modele" not in st.session_state:                                         # V√©rifions qu‚Äôun mod√®le existe
        st.warning("Veuillez d‚Äôabord entra√Æner un mod√®le dans l‚Äôonglet „ÄΩÔ∏è Mod√©lisation.")
    else:
        pipe = st.session_state["pipeline_modele"]                                        # R√©cup√©rons le pipeline

        colpr1, colpr2, colpr3, colpr4 = st.columns(4)                                    # Quatre crit√®res d‚Äôentr√©e
        with colpr1:
            annee_sel = st.selectbox("Ann√©e", sorted(donnees_nettoyees["annee"].dropna().astype(int).unique()))
        with colpr2:
            region_sel = st.selectbox("R√©gion/District", sorted(donnees_nettoyees["regions_districts"].dropna().unique()))
        with colpr3:
            ville_sel = st.selectbox("Ville/Commune", sorted(donnees_nettoyees["villes_communes"].dropna().unique()))
        with colpr4:
            maladie_sel = st.selectbox("Maladie", sorted(donnees_nettoyees["maladie"].dropna().unique()))

        # Construisons un DataFrame d‚Äôune ligne avec ces choix
        saisie = pd.DataFrame({
            "annee": [int(annee_sel)],
            "regions_districts": [region_sel],
            "villes_communes": [ville_sel],
            "maladie": [maladie_sel]
        })

        if st.button("üîÆ Lancer la pr√©diction"):
            # Produisons la pr√©diction via le pipeline entra√Æn√©
            y_hat = pipe.predict(saisie)[0]                                              # R√©cup√©rons la pr√©diction scalaire
            st.success(f"Incidence attendue : **{y_hat:.2f} %**")                        # Affichons un r√©sum√© clair

            # Optionnel : rapprochons de la moyenne historique locale comme rep√®re
            cond = (
                (donnees_nettoyees["annee"] == int(annee_sel)) &
                (donnees_nettoyees["regions_districts"] == region_sel) &
                (donnees_nettoyees["villes_communes"] == ville_sel) &
                (donnees_nettoyees["maladie"] == maladie_sel)
            )
            ref_local = donnees_nettoyees.loc[cond, "incidence_population_pct"].mean()   # Calculons une moyenne de r√©f√©rence
            if not np.isnan(ref_local):
                st.info(f"Moyenne observ√©e (m√™mes filtres, historique) : **{ref_local:.2f} %**")

# =========================
#  SOURCE
# =========================
with onglets[8]:
    st.header("Origine des donn√©es")                                                      # Titre de section
    st.markdown("""
    - **Source ouverte** : *Incidences de maladies sur la population de 2012 √† 2015*.  
    - **Lien** : https://data.gouv.ci/datasets/incidence-de-maladies-sur-la-population-de-2012-a-2015
    """)
    st.write("Utilisez les autres onglets pour naviguer dans l‚Äôanalyse, la mod√©lisation et la pr√©diction.")
