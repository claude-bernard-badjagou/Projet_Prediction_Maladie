
# Application Streamlit : Incidence des maladies (C√¥te d'Ivoire, 2012-2015)

# -------- Imports (tous comment√©s) --------
import streamlit as st                     # Importons Streamlit pour construire l'application web interactive
import streamlit.components.v1 as components  # Importons le module des composants HTML pour int√©grer Pygwalker
import pandas as pd                        # Importons pandas pour charger et manipuler les donn√©es tabulaires
import numpy as np                         # Importons numpy pour quelques op√©rations num√©riques
import plotly.express as px                # Importons Plotly Express pour cr√©er des visualisations interactives
import plotly.graph_objects as go          # Importons Graph Objects pour des graphiques personnalis√©s
from io import StringIO                    # Importons StringIO pour g√©n√©rer un CSV t√©l√©chargeable en m√©moire

# Outils ML
from sklearn.model_selection import train_test_split, cross_val_score  # D√©coupage train/test + validation crois√©e
from sklearn.compose import ColumnTransformer                           # Traitement h√©t√©rog√®ne (num√©rique/cat√©goriel)
from sklearn.preprocessing import OneHotEncoder, StandardScaler         # Encodage cat√©goriel + standardisation num
from sklearn.pipeline import Pipeline                                   # Cha√Ænage pr√©traitements + mod√®le
from sklearn.linear_model import LinearRegression                       # R√©gression lin√©aire
from sklearn.preprocessing import PolynomialFeatures                    # Caract√©ristiques polynomiales (degr√© 2)
from sklearn.ensemble import RandomForestRegressor                      # For√™t al√©atoire r√©gression
from sklearn.neighbors import KNeighborsRegressor                       # KNN r√©gression
from sklearn.neural_network import MLPRegressor                         # R√©seau de neurones (MLP l√©ger)
from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error  # M√©triques (RMSE moderne)

# -------- Configuration globale de la page --------
st.set_page_config(                             # Configurons la page Streamlit pour un rendu propre
    page_title="Incidence maladies CI (2012-2015)",  # D√©finissons le titre de l‚Äôonglet navigateur
    page_icon="moustique_tigre.jpg",                 # D√©finissons l‚Äôic√¥ne de page (image partag√©e)
    layout="wide"                                    # Passons en mode large pour mieux exploiter l‚Äô√©cran
)

# -------- Styles CSS l√©gers pour homog√©n√©iser l'UI --------
st.markdown("""
<style>
/* Donnons un l√©ger arrondi et des ombres aux blocs */
.block { background: #ffffff; padding: 16px; border-radius: 12px;
         box-shadow: 0 2px 10px rgba(0,0,0,0.06); }
/* Mettons en valeur les titres secondaires */
h2, h3 { color: #0D1D2C; }
/* All√©geons l‚Äôapparence des DataFrames */
[data-testid="stDataFrame"] { border: 1px solid #eee; border-radius: 8px; }
/* S√©parateurs visuels confortables */
.section { margin-top: 16px; margin-bottom: 24px; }
</style>
""", unsafe_allow_html=True)

# --------- Fonctions utilitaires (toutes en fran√ßais + commentaires) ---------

@st.cache_data(show_spinner=True)
def charger_donnees_csv(chemin: str) -> pd.DataFrame:
    """Chargeons le fichier CSV pour obtenir le jeu de donn√©es source (unique point d'entr√©e des donn√©es)."""
    # Chargeons le fichier CSV pour alimenter toutes les pages de l'application
    df = pd.read_csv(chemin)  # Lecture simple du fichier CSV "Incidence.csv" fourni dans les ressources
    return df                  # Renvoyons le DataFrame charg√©

def normaliser_noms_colonnes(df: pd.DataFrame) -> pd.DataFrame:
    """Harmonisons les libell√©s de colonnes pour un code robuste, quelles que soient les variantes d'intitul√©s."""
    donnees = df.copy()  # Copions le DataFrame d‚Äôentr√©e pour travailler proprement

    # Table de correspondance des libell√©s h√©t√©rog√®nes vers des noms normalis√©s (sans espaces/accents)
    mapping = {
        "ANNEE": "annee",
        "REGIONS / DISTRICTS": "regions_districts",
        "REGIONS/DISTRICTS": "regions_districts",
        "VILLES / COMMUNES": "villes_communes",
        "VILLES/COMMUNES": "villes_communes",
        "MALADIE": "maladie",
        "INCIDENCE SUR LA POPULATION GENERALE (%)": "incidence_population_pct",
        "INCIDENCE_SUR_LA_POPULATION_GENERALE_(%)": "incidence_population_pct",
    }

    # Renommons les colonnes pr√©sentes dans le mapping
    colonnes_renommees = {c: mapping[c] for c in donnees.columns if c in mapping}
    donnees = donnees.rename(columns=colonnes_renommees)

    # Pour plus de robustesse, normalisons tout le reste (minuscules + rempla√ßons espaces par underscore)
    donnees.columns = [c.strip().lower().replace(" ", "_") for c in donnees.columns]
    return donnees

def typer_colonnes(donnees: pd.DataFrame) -> pd.DataFrame:
    """Typage : convertissons ann√©e en float64 (√©vite les soucis Arrow), incidence en float, autres en string."""
    df = donnees.copy()

    # Chargeons la colonne annee en float64 (garde les NaN et reste Arrow-friendly)
    if "annee" in df.columns:
        df["annee"] = pd.to_numeric(df["annee"], errors="coerce")  # float64 + NaN

    # Chargeons l‚Äôincidence en float64
    if "incidence_population_pct" in df.columns:
        df["incidence_population_pct"] = pd.to_numeric(df["incidence_population_pct"], errors="coerce")

    # For√ßons les colonnes cat√©gorielles en string pour √©viter les surprises plus tard
    for col in ["regions_districts", "villes_communes", "maladie"]:
        if col in df.columns:
            df[col] = df[col].astype("string")

    return df

def statistiques_rapides(df: pd.DataFrame) -> pd.DataFrame:
    """Produisons un tableau synth√©tique des statistiques descriptives num√©riques pour survol rapide."""
    stats = df.select_dtypes(include=[np.number]).describe().T  # n, moyenne, std, min, max, quartiles
    return stats

def valeurs_manquantes(df: pd.DataFrame) -> pd.DataFrame:
    """Comptons les valeurs manquantes par colonne pour cibler le nettoyage."""
    na = df.isna().sum().sort_values(ascending=False)
    return pd.DataFrame({"colonne": na.index, "manquants": na.values})

def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoyons : supprimons les doublons, imputons les NA (mode sur cat√©goriel, m√©diane sur num√©rique)."""
    donnees = df.copy()
    donnees = donnees.drop_duplicates()

    cols_num = donnees.select_dtypes(include=[np.number]).columns.tolist()
    cols_cat = [c for c in donnees.columns if c not in cols_num]

    # Imputons les valeurs manquantes num√©riques par la m√©diane (robuste aux outliers)
    for c in cols_num:
        if donnees[c].isna().any():
            donnees[c] = donnees[c].fillna(donnees[c].median())

    # Imputons les valeurs manquantes cat√©gorielles par le mode (valeur la plus fr√©quente)
    for c in cols_cat:
        if donnees[c].isna().any():
            mode = donnees[c].mode(dropna=True)
            if len(mode) > 0:
                donnees[c] = donnees[c].fillna(mode.iloc[0])

    return donnees

def detecter_valeurs_aberrantes(df: pd.DataFrame, z=3.0) -> pd.DataFrame:
    """D√©tectons les valeurs aberrantes (z-score > seuil) pour les colonnes num√©riques."""
    dnum = df.select_dtypes(include=[np.number])
    if dnum.empty:
        return df.iloc[0:0]
    zscores = (dnum - dnum.mean()) / dnum.std(ddof=0)
    masque_out = (zscores.abs() > z).any(axis=1)
    return df.loc[masque_out]

def telecharger_csv(df: pd.DataFrame) -> bytes:
    """Pr√©parons un CSV t√©l√©chargeable (en m√©moire) pour r√©cup√©rer les donn√©es nettoy√©es."""
    buffer = StringIO()
    df.to_csv(buffer, index=False)
    return buffer.getvalue().encode("utf-8")

def rendre_arrow_compatible(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convertissons les types pandas potentiellement probl√©matiques (nullable, objets mixtes)
    vers des types Arrow-compatibles avant affichage Streamlit.
    """
    dfa = df.copy()
    # Rempla√ßons pd.NA par np.nan
    dfa = dfa.replace({pd.NA: np.nan})
    # Objets mixtes -> string si ambigu
    for col in dfa.columns:
        if dfa[col].dtype == "object":
            types_uniques = set(type(x) for x in dfa[col].dropna().head(1000))
            if len(types_uniques) > 1:
                dfa[col] = dfa[col].astype("string")
    return dfa

# --------- Chargement unique & pr√©paration initiale ---------
# Chargeons le fichier 'Incidence.csv' pour alimenter l'int√©gralit√© de l'app, puis normalisons/typons/Nettoyons
donnees_brutes = charger_donnees_csv("Incidence.csv")          # Chargeons le fichier pour obtenir les donn√©es d'origine
donnees = normaliser_noms_colonnes(donnees_brutes)             # Normalisons les libell√©s pour unifier le code
donnees = typer_colonnes(donnees)                              # Typage coh√©rent (float64 + string)
donnees_nettoyees = nettoyer_donnees(donnees)                  # Appliquons un nettoyage simple et robuste

# Stockons dans la session pour r√©utiliser partout sans rechargement
if "donnees_nettoyees" not in st.session_state:
    st.session_state["donnees_nettoyees"] = donnees_nettoyees

# (Option) Auto-entra√Ænement au d√©marrage pour que l‚Äôonglet Pr√©diction soit utilisable imm√©diatement
AUTO_TRAIN_ON_START = True  # Mets False si tu pr√©f√®res entra√Æner manuellement dans l‚Äôonglet Mod√©lisation

def construire_pipeline_defaut():
    """Construisons un pipeline par d√©faut (pr√©traitements + RandomForest) pour l'entra√Ænement au d√©marrage."""
    colonnes_numeriques = ["annee"]
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]
    preprocesseur = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles),
        ]
    )
    modele = RandomForestRegressor(n_estimators=300, random_state=42)
    pipe = Pipeline([("prep", preprocesseur), ("mod", modele)])
    return pipe

def entrainer_au_demarrage_si_absent(df):
    """Entra√Ænons un pipeline de base et stockons-le en session si aucun mod√®le n'existe encore."""
    X = df[["annee", "regions_districts", "villes_communes", "maladie"]]
    y = df["incidence_population_pct"]
    pipe = construire_pipeline_defaut()
    pipe.fit(X, y)  # Entra√Ænons le pipeline sur toutes les donn√©es pour disposer d'un mod√®le initial
    st.session_state["pipeline_modele"] = pipe
    st.session_state["modele_info"] = "Mod√®le par d√©faut (RandomForest) entra√Æn√© au d√©marrage."

if AUTO_TRAIN_ON_START and "pipeline_modele" not in st.session_state:
    entrainer_au_demarrage_si_absent(st.session_state["donnees_nettoyees"])

# --------- Barre de navigation horizontale (onglets) ---------
onglets = st.tabs([
    "üè† Accueil", "üìí Informations", "üõ† Exploration", "üßπ Pr√©paration",
    "üîç Visualisations", "üëÄ Explorateur", "„ÄΩÔ∏è Mod√©lisation", "‚óª Pr√©diction", "üõñ Source"
])

# =========================
# üè† ACCUEIL
# =========================
with onglets[0]:
    st.title("Incidence des maladies en C√¥te d‚ÄôIvoire (2012‚Äì2015)")
    col1, col2 = st.columns([1, 2], gap="large")

    with col1:
        st.image("moustique_tigre.jpg", use_column_width=True, caption="Aedes albopictus (moustique tigre)")

    with col2:
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Objectif de l‚Äôapplication</h3>
        Cette application interactive permet d‚Äôexplorer, de visualiser et de mod√©liser 
        l‚Äôincidence de plusieurs maladies en C√¥te d‚ÄôIvoire entre 2012 et 2015.
        Elle propose des graphiques interactifs, un explorateur visuel libre (Pygwalker),
        ainsi que plusieurs mod√®les pr√©dictifs (R√©gression, Random Forest, KNN, ANN).
        </div>""", unsafe_allow_html=True)

        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Probl√®me adress√©</h3>
        Comment transformer des donn√©es brutes de sant√© publique en <b>indicateurs actionnables</b> 
        et en <b>pr√©dictions</b> fiables pour aider √† la d√©cision (priorisation des zones et des pathologies) ?
        </div>""", unsafe_allow_html=True)

        st.markdown("""<div class="block" style="text-align:justify">
        <h3>R√©sultats attendus</h3>
        Un <b>outil unique</b> permettant : 
        (1) l‚Äôanalyse rapide des tendances,
        (2) l‚Äôidentification des disparit√©s r√©gionales,
        (3) la pr√©diction de l‚Äôincidence selon ann√©e/r√©gion/ville/maladie.
        </div>""", unsafe_allow_html=True)

# =========================
# üìí INFORMATIONS
# =========================
with onglets[1]:
    st.header("Informations sur les donn√©es")
    st.write("**Aper√ßu des premi√®res lignes (jeu de donn√©es d‚Äôorigine)**")
    st.dataframe(rendre_arrow_compatible(donnees_brutes.head()), use_container_width=True)

    st.write("**Libell√©s de colonnes normalis√©s (utilis√©s en interne)**")
    st.json({
        "annee": "Ann√©e d‚Äôobservation (2012‚Äì2015)",
        "regions_districts": "R√©gion ou district sanitaire",
        "villes_communes": "Ville ou commune",
        "maladie": "Type de pathologie",
        "incidence_population_pct": "Incidence sur la population g√©n√©rale (en %)"
    })

# =========================
# üõ† EXPLORATION  (tables empil√©es verticalement)
# =========================
with onglets[2]:
    st.header("Exploration des donn√©es")

    st.subheader("Dimensions")
    st.write(f"**Nombre de lignes** : {donnees_nettoyees.shape[0]}")
    st.write(f"**Nombre de colonnes** : {donnees_nettoyees.shape[1]}")

    st.subheader("Types de donn√©es (dtypes)")
    st.dataframe(rendre_arrow_compatible(donnees_nettoyees.dtypes.to_frame("dtype")), use_container_width=True)

    st.subheader("Valeurs manquantes (par colonne)")
    st.dataframe(rendre_arrow_compatible(valeurs_manquantes(donnees_nettoyees)), use_container_width=True)

    st.subheader("Statistiques descriptives (variables num√©riques)")
    st.dataframe(rendre_arrow_compatible(statistiques_rapides(donnees_nettoyees)), use_container_width=True)

    st.subheader("Valeurs aberrantes potentielles (z-score > 3)")
    outliers = detecter_valeurs_aberrantes(donnees_nettoyees)
    if outliers.empty:
        st.info("Aucune ligne ne d√©passe le seuil de z-score s√©lectionn√© (3.0).")
    else:
        st.dataframe(rendre_arrow_compatible(outliers), use_container_width=True)

# =========================
# üßπ PR√âPARATION (manipulation)
# =========================
with onglets[3]:
    st.header("Pr√©paration et export des donn√©es")

    st.write("**Aper√ßu apr√®s nettoyage (doublons supprim√©s, NA imput√©s)**")
    st.dataframe(rendre_arrow_compatible(donnees_nettoyees.head(20)), use_container_width=True)

    st.download_button(
        label="üì• T√©l√©charger les donn√©es nettoy√©es (CSV)",
        data=telecharger_csv(donnees_nettoyees),
        file_name="incidence_nettoyee.csv",
        mime="text/csv"
    )

# =========================
# üîç VISUALISATIONS
# =========================
with onglets[4]:
    st.header("Visualisations interactives")
    dfv = donnees_nettoyees

    colf1, colf2, colf3 = st.columns(3)
    with colf1:
        maladies_dispo = sorted(dfv["maladie"].dropna().unique().tolist())
        choix_maladie = st.selectbox("Choisir une maladie", maladies_dispo, index=0)
    with colf2:
        annees_dispo = sorted(dfv["annee"].dropna().unique().astype(int).tolist())
        choix_annees = st.multiselect("Filtrer par ann√©e", annees_dispo, default=annees_dispo)
    with colf3:
        regions_dispo = ["(Toutes)"] + sorted(dfv["regions_districts"].dropna().unique().tolist())
        choix_region = st.selectbox("Filtrer par r√©gion/district", regions_dispo, index=0)

    dff = dfv[dfv["maladie"] == choix_maladie]
    dff = dff[dff["annee"].isin(choix_annees)]
    if choix_region != "(Toutes)":
        dff = dff[dff["regions_districts"] == choix_region]

    st.subheader("√âvolution de l‚Äôincidence (%) dans le temps")
    if len(dff) == 0:
        st.warning("Aucune donn√©e pour ce filtre.")
    else:
        evol = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
        fig1 = px.line(
            evol, x="annee", y="incidence_population_pct", markers=True,
            labels={"annee": "Ann√©e", "incidence_population_pct": "Incidence (%)"},
            title=f"√âvolution ‚Äî {choix_maladie}"
        )
        st.plotly_chart(fig1, use_container_width=True)

    st.subheader("Comparaison des r√©gions/districts (moyenne)")
    comp = dfv[dfv["maladie"] == choix_maladie]
    comp = comp[comp["annee"].isin(choix_annees)]
    comp = comp.groupby("regions_districts", dropna=True)["incidence_population_pct"].mean().reset_index()
    comp = comp.sort_values("incidence_population_pct", ascending=False).head(20)
    fig2 = px.bar(
        comp, x="regions_districts", y="incidence_population_pct",
        labels={"regions_districts": "R√©gion/District", "incidence_population_pct": "Incidence (%)"},
        title=f"Top r√©gions ‚Äî {choix_maladie} (moyenne {min(choix_annees)}‚Äì{max(choix_annees)})"
    )
    fig2.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig2, use_container_width=True)

    st.subheader("R√©partition par ann√©e (moyenne)")
    rep = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
    fig3 = px.pie(rep, names="annee", values="incidence_population_pct", title="Part relative moyenne par ann√©e", hole=0.35)
    st.plotly_chart(fig3, use_container_width=True)

# =========================
# üëÄ EXPLORATEUR (Pygwalker)
# =========================
with onglets[5]:
    st.header("Explorateur visuel libre (Pygwalker)")
    st.info("Astuce : glissez-d√©posez les champs √† gauche pour cr√©er vos vues interactives.")

    # Petit test pour v√©rifier que les composants HTML fonctionnent
    components.html("<div style='padding:8px;border:1px solid #eee;border-radius:8px'>‚úÖ Test composant HTML OK</div>", height=60)

    try:
        # M√©thode recommand√©e : API Streamlit de Pygwalker
        from pygwalker.api.streamlit import init_streamlit_comm, get_streamlit_html
        init_streamlit_comm()  # Initialise la communication Streamlit <-> Pygwalker
        pyg_html = get_streamlit_html(donnees_nettoyees, use_kernel_calc=True, spec=None)
        components.html(pyg_html, height=950, scrolling=True)
        st.success("Pygwalker (API Streamlit) charg√©.")
    except Exception as e_api:
        # Fallback : m√©thode g√©n√©rique HTML
        try:
            import pygwalker as pyg
            st.info("Chargement fallback Pygwalker (m√©thode g√©n√©rique).")
            # Tentons diff√©rentes valeurs d‚Äôenvironnement si n√©cessaire
            pyg_html = None
            for env in ("streamlit", "Jupyter", None):
                try:
                    pyg_html = pyg.to_html(donnees_nettoyees, env=env) if env else pyg.to_html(donnees_nettoyees)
                    if pyg_html and ("<iframe" in pyg_html or "<div" in pyg_html):
                        break
                except Exception:
                    pass
            if not pyg_html:
                raise RuntimeError("Impossible de g√©n√©rer le HTML Pygwalker via la m√©thode g√©n√©rique.")
            components.html(pyg_html, height=950, scrolling=True)
            st.success("Pygwalker (fallback) charg√©.")
        except Exception as e_fallback:
            st.error("Pygwalker n‚Äôa pas pu √™tre rendu. D√©tails ci-dessous :")
            st.exception(e_api if e_api else e_fallback)
            st.caption("V√©rifie `pygwalker` et `streamlit` dans requirements.txt.")

# =========================
# „ÄΩÔ∏è MOD√âLISATION
# =========================
with onglets[6]:
    st.header("Mod√©lisation supervis√©e (r√©gression)")

    # Param√®tres utilisateur
    colp1, colp2, colp3 = st.columns(3)
    with colp1:
        type_modele = st.selectbox(
            "Choisir un mod√®le",
            ["R√©gression lin√©aire", "R√©gression polynomiale", "For√™t al√©atoire", "KNN r√©gression", "R√©seau de neurones (ANN)"]
        )
    with colp2:
        test_size = st.slider("Taille test (%)", 10, 40, 20, step=5)
    with colp3:
        random_state = st.number_input("Graine al√©atoire", value=42, step=1)

    # Pr√©paration X / y
    X = donnees_nettoyees[["annee", "regions_districts", "villes_communes", "maladie"]]
    y = donnees_nettoyees["incidence_population_pct"]

    colonnes_numeriques = ["annee"]
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]

    preprocesseur = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles)
        ]
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size/100, random_state=int(random_state)
    )

    # S√©lection du pipeline mod√®le
    if type_modele == "R√©gression lin√©aire":
        modele = LinearRegression()
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    elif type_modele == "R√©gression polynomiale":
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("poly", PolynomialFeatures(degree=2, include_bias=False)),
            ("mod", LinearRegression())
        ])

    elif type_modele == "For√™t al√©atoire":
        modele = RandomForestRegressor(n_estimators=300, random_state=int(random_state))
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    elif type_modele == "KNN r√©gression":
        modele = KNeighborsRegressor(n_neighbors=7)
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    else:  # R√©seau de neurones (ANN)
        modele = MLPRegressor(hidden_layer_sizes=(128, 64), activation="relu", solver="adam",
                              max_iter=1000, random_state=int(random_state))
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    # Entra√Ænement + √âvaluation
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = root_mean_squared_error(y_test, y_pred)  # ‚úÖ plus de param√®tre squared=False

    colm1, colm2, colm3 = st.columns(3)
    colm1.metric("R¬≤", f"{r2:0.3f}")
    colm2.metric("MAE", f"{mae:0.3f}")
    colm3.metric("RMSE", f"{rmse:0.3f}")

    with st.expander("Voir la validation crois√©e (5 plis)"):
        scores = cross_val_score(pipeline, X, y, cv=5, scoring="r2")
        st.write("Scores R¬≤ par pli :", [f"{s:0.3f}" for s in scores])
        st.write("R¬≤ moyen :", f"{np.mean(scores):0.3f} ¬± {np.std(scores):0.3f}")

    # Pipeline disponible pour l‚Äôonglet Pr√©diction
    st.session_state["pipeline_modele"] = pipeline
    st.success("Mod√®le entra√Æn√© et stock√© pour l‚Äôonglet ‚óª Pr√©diction.")

# =========================
# ‚óª PR√âDICTION
# =========================
with onglets[7]:
    st.header("Pr√©dire l‚Äôincidence (%) selon vos s√©lections")

    if "pipeline_modele" not in st.session_state:
        st.warning("Veuillez d‚Äôabord entra√Æner un mod√®le dans l‚Äôonglet „ÄΩÔ∏è Mod√©lisation.")
    else:
        pipe = st.session_state["pipeline_modele"]

        if "modele_info" in st.session_state:
            st.info(st.session_state["modele_info"])

        colpr1, colpr2, colpr3, colpr4 = st.columns(4)
        with colpr1:
            annee_sel = st.selectbox("Ann√©e", sorted(donnees_nettoyees["annee"].dropna().astype(int).unique()))
        with colpr2:
            region_sel = st.selectbox("R√©gion/District", sorted(donnees_nettoyees["regions_districts"].dropna().unique()))
        with colpr3:
            ville_sel = st.selectbox("Ville/Commune", sorted(donnees_nettoyees["villes_communes"].dropna().unique()))
        with colpr4:
            maladie_sel = st.selectbox("Maladie", sorted(donnees_nettoyees["maladie"].dropna().unique()))

        saisie = pd.DataFrame({
            "annee": [int(annee_sel)],
            "regions_districts": [region_sel],
            "villes_communes": [ville_sel],
            "maladie": [maladie_sel]
        })

        if st.button("üîÆ Lancer la pr√©diction"):
            y_hat = pipe.predict(saisie)[0]
            st.success(f"Incidence attendue : **{y_hat:.2f} %**")

            cond = (
                (donnees_nettoyees["annee"] == int(annee_sel)) &
                (donnees_nettoyees["regions_districts"] == region_sel) &
                (donnees_nettoyees["villes_communes"] == ville_sel) &
                (donnees_nettoyees["maladie"] == maladie_sel)
            )
            ref_local = donnees_nettoyees.loc[cond, "incidence_population_pct"].mean()
            if not np.isnan(ref_local):
                st.info(f"Moyenne observ√©e (m√™mes filtres, historique) : **{ref_local:.2f} %**")

# =========================
# üõñ SOURCE
# =========================
with onglets[8]:
    st.header("Origine des donn√©es")
    st.markdown("""
    - **Source ouverte** : *Incidences de maladies sur la population de 2012 √† 2015*.  
    - **Lien** : https://data.gouv.ci/datasets/incidence-de-maladies-sur-la-population-de-2012-a-2015
    """)
    st.write("Utilisez les autres onglets pour naviguer dans l‚Äôanalyse, la mod√©lisation et la pr√©diction.")
