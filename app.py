
# Application Streamlit : Incidence des maladies (C√¥te d'Ivoire, 2012-2015)


# -------- Imports (tous comment√©s) --------
import streamlit as st                                 # Application web interactive
import streamlit.components.v1 as components           # Composants HTML (int√©gration Pygwalker)
import pandas as pd                                    # Manipulation de donn√©es tabulaires
import numpy as np                                     # Calcul num√©rique
import plotly.express as px                            # Visualisations interactives
import plotly.graph_objects as go                      # Graphiques personnalis√©s
from io import StringIO                                # Tampon texte pour export CSV

# Outils ML
from sklearn.model_selection import train_test_split, cross_val_score  # Split + CV
from sklearn.compose import ColumnTransformer                           # Pr√©traitement h√©t√©rog√®ne
from sklearn.preprocessing import OneHotEncoder, StandardScaler         # Encodage + standardisation
from sklearn.pipeline import Pipeline                                   # Pipeline pr√©traitement+mod√®le
from sklearn.linear_model import LinearRegression                       # R√©gression lin√©aire
from sklearn.preprocessing import PolynomialFeatures                    # Caract√©ristiques polynomiales
from sklearn.ensemble import RandomForestRegressor                      # For√™t al√©atoire
from sklearn.neighbors import KNeighborsRegressor                       # KNN
from sklearn.neural_network import MLPRegressor                         # R√©seau de neurones (MLP)
from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error  # M√©triques

# -------- Options pandas (pr√©venir les downcasting silencieux) --------
pd.set_option('future.no_silent_downcasting', True)  # √âvite les changements silencieux de dtype futurs

# -------- Configuration globale de la page --------
st.set_page_config(
    page_title="Incidence maladies CI (2012-2015)",   # Titre de l‚Äôonglet navigateur
    page_icon="moustique_tigre.jpg",                  # Ic√¥ne de page
    layout="wide"                                     # Mise en page large
)

# -------- Styles CSS l√©gers pour homog√©n√©iser l'UI --------
st.markdown("""
<style>
.block { background:#fff; padding:16px; border-radius:12px; box-shadow:0 2px 10px rgba(0,0,0,0.06); }
h2, h3 { color:#0D1D2C; }
[data-testid="stDataFrame"] { border:1px solid #eee; border-radius:8px; }
.section { margin-top:16px; margin-bottom:24px; }
</style>
""", unsafe_allow_html=True)

# --------- Fonctions utilitaires (toutes en fran√ßais + commentaires) ---------

@st.cache_data(show_spinner=True)
def charger_donnees_csv(chemin: str) -> pd.DataFrame:
    """Chargeons le fichier CSV pour obtenir le jeu de donn√©es source (unique point d'entr√©e)."""
    df = pd.read_csv(chemin)                      # Lecture du fichier CSV "Incidence.csv"
    return df                                     # Renvoyons les donn√©es brutes

def normaliser_noms_colonnes(df: pd.DataFrame) -> pd.DataFrame:
    """Harmonisons les libell√©s de colonnes pour un code robuste, malgr√© les variantes d'intitul√©s."""
    donnees = df.copy()                           # Copions le DataFrame pour travailler proprement
    mapping = {                                   # Table de correspondance des noms h√©t√©rog√®nes
        "ANNEE": "annee",
        "REGIONS / DISTRICTS": "regions_districts",
        "REGIONS/DISTRICTS": "regions_districts",
        "VILLES / COMMUNES": "villes_communes",
        "VILLES/COMMUNES": "villes_communes",
        "MALADIE": "maladie",
        "INCIDENCE SUR LA POPULATION GENERALE (%)": "incidence_population_pct",
        "INCIDENCE_SUR_LA_POPULATION_GENERALE_(%)": "incidence_population_pct",
    }
    donnees = donnees.rename(columns={c: mapping[c] for c in donnees.columns if c in mapping})  # Renommage cibl√©
    donnees.columns = [c.strip().lower().replace(" ", "_") for c in donnees.columns]            # Normalisation globale
    return donnees

def typer_colonnes(donnees: pd.DataFrame) -> pd.DataFrame:
    """Typage : ann√©e en float64 (compatible Arrow), incidence en float64, autres en string."""
    df = donnees.copy()
    if "annee" in df.columns:
        df["annee"] = pd.to_numeric(df["annee"], errors="coerce")                   # Ann√©e -> float64 (g√®re NaN)
    if "incidence_population_pct" in df.columns:
        df["incidence_population_pct"] = pd.to_numeric(df["incidence_population_pct"], errors="coerce")  # Float64
    for col in ["regions_districts", "villes_communes", "maladie"]:
        if col in df.columns:
            df[col] = df[col].astype("string")                                      # Cat√©gories -> string pandas
    return df

def statistiques_rapides(df: pd.DataFrame) -> pd.DataFrame:
    """Produisons un tableau synth√©tique des statistiques descriptives num√©riques."""
    return df.select_dtypes(include=[np.number]).describe().T

def valeurs_manquantes(df: pd.DataFrame) -> pd.DataFrame:
    """Comptons les valeurs manquantes par colonne pour cibler le nettoyage."""
    na = df.isna().sum().sort_values(ascending=False)
    return pd.DataFrame({"colonne": na.index, "manquants": na.values})

def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoyons : supprimons les doublons, imputons NA (m√©diane sur num√©rique, mode sur cat√©goriel)."""
    donnees = df.copy().drop_duplicates()                                             # Supprimons les doublons
    cols_num = donnees.select_dtypes(include=[np.number]).columns.tolist()            # Num√©riques
    cols_cat = [c for c in donnees.columns if c not in cols_num]                      # Cat√©gorielles
    for c in cols_num:                                                                
        if donnees[c].isna().any():                                                   # Imputation num√©rique
            donnees[c] = donnees[c].fillna(donnees[c].median())
    for c in cols_cat:
        if donnees[c].isna().any():                                                   # Imputation cat√©gorielle
            mode = donnees[c].mode(dropna=True)
            if len(mode) > 0:
                donnees[c] = donnees[c].fillna(mode.iloc[0])
    return donnees

def detecter_valeurs_aberrantes(df: pd.DataFrame, z=3.0) -> pd.DataFrame:
    """D√©tectons les valeurs aberrantes (z-score > seuil) pour les colonnes num√©riques."""
    dnum = df.select_dtypes(include=[np.number])
    if dnum.empty:
        return df.iloc[0:0]
    zscores = (dnum - dnum.mean()) / dnum.std(ddof=0)                                 # Z-scores (√©cart-type population)
    masque_out = (zscores.abs() > z).any(axis=1)                                      # Lignes avec au moins un d√©passement
    return df.loc[masque_out]

def telecharger_csv(df: pd.DataFrame) -> bytes:
    """Pr√©parons un CSV t√©l√©chargeable (en m√©moire) pour r√©cup√©rer les donn√©es nettoy√©es."""
    buffer = StringIO()
    df.to_csv(buffer, index=False)
    return buffer.getvalue().encode("utf-8")

def rendre_arrow_compatible(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convertissons les types pandas potentiellement probl√©matiques (nullable, objets mixtes)
    vers des types Arrow-compatibles avant affichage Streamlit, sans downcasting silencieux.
    """
    dfa = df.copy()
    dfa = dfa.replace({pd.NA: np.nan})                     # Rempla√ßons explicitement pd.NA par np.nan
    dfa.infer_objects(copy=False)                          # Alignons les dtypes object -> types concrets (sans downcasting silencieux)
    # Colonnes 'object' h√©t√©rog√®nes -> string si m√©lange de types
    for col in dfa.columns:
        if dfa[col].dtype == "object":
            types_uniques = set(type(x) for x in dfa[col].dropna().head(1000))
            if len(types_uniques) > 1:
                dfa[col] = dfa[col].astype("string")
    return dfa

# --------- Chargement unique & pr√©paration initiale ---------
# Chargeons le fichier 'Incidence.csv' pour alimenter l'app, puis normalisons/typons/nettoyons
donnees_brutes = charger_donnees_csv("Incidence.csv")          # Chargeons le fichier source
donnees = normaliser_noms_colonnes(donnees_brutes)             # Uniformisons les noms de colonnes
donnees = typer_colonnes(donnees)                              # Typage Arrow-friendly
donnees_nettoyees = nettoyer_donnees(donnees)                  # Nettoyage simple & robuste

# Stockons dans la session pour r√©utiliser partout
if "donnees_nettoyees" not in st.session_state:
    st.session_state["donnees_nettoyees"] = donnees_nettoyees

# --------- (Option) Auto-entra√Ænement au d√©marrage (robuste) ---------
AUTO_TRAIN_ON_START = True  # Mets False si tu pr√©f√®res entra√Æner manuellement dans l‚Äôonglet Mod√©lisation

def construire_pipeline_defaut():
    """Pipeline par d√©faut (pr√©traitements + RandomForest)."""
    colonnes_numeriques = ["annee"]
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]
    preprocesseur = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles),
        ]
    )
    modele = RandomForestRegressor(n_estimators=300, random_state=42)
    return Pipeline([("prep", preprocesseur), ("mod", modele)])

def entrainer_au_demarrage_si_absent(df: pd.DataFrame):
    """
    Entra√Æne un mod√®le de base si absent.
    - Supprime les lignes incompl√®tes (dropna) pour √©viter un crash.
    - Capture les exceptions pour ne pas bloquer le rendu des onglets.
    """
    try:
        data = df[["annee", "regions_districts", "villes_communes", "maladie", "incidence_population_pct"]].dropna()
        if data.empty:
            st.warning("Auto-entra√Ænement ignor√© : donn√©es insuffisantes (trop de valeurs manquantes).")
            return
        X = data[["annee", "regions_districts", "villes_communes", "maladie"]]
        y = data["incidence_population_pct"]
        pipe = construire_pipeline_defaut()
        pipe.fit(X, y)
        st.session_state["pipeline_modele"] = pipe
        st.session_state["modele_info"] = "Mod√®le par d√©faut (RandomForest) entra√Æn√© au d√©marrage."
    except Exception as e:
        st.warning("Auto-entra√Ænement au d√©marrage non r√©alis√© (erreur captur√©e). Consulte l‚Äôonglet „ÄΩÔ∏è Mod√©lisation.")
        st.caption(f"D√©tail : {type(e).__name__}: {e}")

if AUTO_TRAIN_ON_START and "pipeline_modele" not in st.session_state:
    entrainer_au_demarrage_si_absent(st.session_state["donnees_nettoyees"])

# --------- Barre de navigation horizontale (onglets) ---------
onglets = st.tabs([
    "üè† Accueil", "üìí Informations", "üõ† Exploration", "üßπ Pr√©paration",
    "üîç Visualisations", "üëÄ Explorateur", "„ÄΩÔ∏è Mod√©lisation", "‚óª Pr√©diction", "üõñ Source"
])

# =========================
# üè† ACCUEIL
# =========================
with onglets[0]:
    st.title("Incidence des maladies en C√¥te d‚ÄôIvoire (2012‚Äì2015)")
    col1, col2 = st.columns([1, 2], gap="large")
    with col1:
        st.image("moustique_tigre.jpg", use_column_width=True, caption="Aedes albopictus (moustique tigre)")
    with col2:
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Objectif de l‚Äôapplication</h3>
        Cette application interactive permet d‚Äôexplorer, de visualiser et de mod√©liser 
        l‚Äôincidence de plusieurs maladies en C√¥te d‚ÄôIvoire entre 2012 et 2015.
        Elle propose des graphiques interactifs, un explorateur visuel libre (Pygwalker),
        ainsi que plusieurs mod√®les pr√©dictifs (R√©gression, Random Forest, KNN, ANN).
        </div>""", unsafe_allow_html=True)
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>Probl√®me adress√©</h3>
        Comment transformer des donn√©es brutes de sant√© publique en <b>indicateurs actionnables</b> 
        et en <b>pr√©dictions</b> fiables pour aider √† la d√©cision (priorisation des zones et des pathologies) ?
        </div>""", unsafe_allow_html=True)
        st.markdown("""<div class="block" style="text-align:justify">
        <h3>R√©sultats attendus</h3>
        Un <b>outil unique</b> permettant : 
        (1) l‚Äôanalyse rapide des tendances,
        (2) l‚Äôidentification des disparit√©s r√©gionales,
        (3) la pr√©diction de l‚Äôincidence selon ann√©e/r√©gion/ville/maladie.
        </div>""", unsafe_allow_html=True)

# =========================
# üìí INFORMATIONS
# =========================
with onglets[1]:
    st.header("Informations sur les donn√©es")
    st.write("**Aper√ßu des premi√®res lignes (jeu de donn√©es d‚Äôorigine)**")
    st.dataframe(rendre_arrow_compatible(donnees_brutes.head()), use_container_width=True)

    st.write("**Libell√©s de colonnes normalis√©s (utilis√©s en interne)**")
    st.json({
        "annee": "Ann√©e d‚Äôobservation (2012‚Äì2015)",
        "regions_districts": "R√©gion ou district sanitaire",
        "villes_communes": "Ville ou commune",
        "maladie": "Type de pathologie",
        "incidence_population_pct": "Incidence sur la population g√©n√©rale (en %)"
    })

# =========================
# üõ† EXPLORATION  (tables empil√©es verticalement)
# =========================
with onglets[2]:
    st.header("Exploration des donn√©es")

    st.subheader("Dimensions")
    st.write(f"**Nombre de lignes** : {donnees_nettoyees.shape[0]}")
    st.write(f"**Nombre de colonnes** : {donnees_nettoyees.shape[1]}")

    st.subheader("Types de donn√©es (dtypes)")
    st.dataframe(rendre_arrow_compatible(donnees_nettoyees.dtypes.to_frame("dtype")), use_container_width=True)

    st.subheader("Valeurs manquantes (par colonne)")
    st.dataframe(rendre_arrow_compatible(valeurs_manquantes(donnees_nettoyees)), use_container_width=True)

    st.subheader("Statistiques descriptives (variables num√©riques)")
    st.dataframe(rendre_arrow_compatible(statistiques_rapides(donnees_nettoyees)), use_container_width=True)

    st.subheader("Valeurs aberrantes potentielles (z-score > 3)")
    outliers = detecter_valeurs_aberrantes(donnees_nettoyees)
    if outliers.empty:
        st.info("Aucune ligne ne d√©passe le seuil de z-score s√©lectionn√© (3.0).")
    else:
        st.dataframe(rendre_arrow_compatible(outliers), use_container_width=True)

# =========================
# üßπ PR√âPARATION (manipulation)
# =========================
with onglets[3]:
    st.header("Pr√©paration et export des donn√©es")
    st.write("**Aper√ßu apr√®s nettoyage (doublons supprim√©s, NA imput√©s)**")
    st.dataframe(rendre_arrow_compatible(donnees_nettoyees.head(20)), use_container_width=True)
    st.download_button(
        label="üì• T√©l√©charger les donn√©es nettoy√©es (CSV)",
        data=telecharger_csv(donnees_nettoyees),
        file_name="incidence_nettoyee.csv",
        mime="text/csv"
    )

# =========================
# üîç VISUALISATIONS
# =========================
with onglets[4]:
    st.header("Visualisations interactives")
    dfv = donnees_nettoyees

    colf1, colf2, colf3 = st.columns(3)
    with colf1:
        maladies_dispo = sorted(dfv["maladie"].dropna().unique().tolist())
        choix_maladie = st.selectbox("Choisir une maladie", maladies_dispo, index=0)
    with colf2:
        annees_dispo = sorted(dfv["annee"].dropna().unique().astype(int).tolist())
        choix_annees = st.multiselect("Filtrer par ann√©e", annees_dispo, default=annees_dispo)
    with colf3:
        regions_dispo = ["(Toutes)"] + sorted(dfv["regions_districts"].dropna().unique().tolist())
        choix_region = st.selectbox("Filtrer par r√©gion/district", regions_dispo, index=0)

    # Filtrage
    dff = dfv[dfv["maladie"] == choix_maladie]
    dff = dff[dff["annee"].isin(choix_annees)]
    if choix_region != "(Toutes)":
        dff = dff[dff["regions_districts"] == choix_region]

    st.subheader("√âvolution de l‚Äôincidence (%) dans le temps")
    if len(dff) == 0:
        st.warning("Aucune donn√©e pour ce filtre.")
    else:
        evol = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
        fig1 = px.line(
            evol, x="annee", y="incidence_population_pct", markers=True,
            labels={"annee": "Ann√©e", "incidence_population_pct": "Incidence (%)"},
            title=f"√âvolution ‚Äî {choix_maladie}"
        )
        st.plotly_chart(fig1, use_container_width=True)

    st.subheader("Comparaison des r√©gions/districts (moyenne)")
    comp = dfv[dfv["maladie"] == choix_maladie]
    comp = comp[comp["annee"].isin(choix_annees)]
    comp = comp.groupby("regions_districts", dropna=True)["incidence_population_pct"].mean().reset_index()
    comp = comp.sort_values("incidence_population_pct", ascending=False).head(20)
    fig2 = px.bar(
        comp, x="regions_districts", y="incidence_population_pct",
        labels={"regions_districts": "R√©gion/District", "incidence_population_pct": "Incidence (%)"},
        title=f"Top r√©gions ‚Äî {choix_maladie} (moyenne {min(choix_annees)}‚Äì{max(choix_annees)})"
    )
    fig2.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig2, use_container_width=True)

    st.subheader("R√©partition par ann√©e (moyenne)")
    rep = dff.groupby("annee", dropna=True)["incidence_population_pct"].mean().reset_index()
    fig3 = px.pie(rep, names="annee", values="incidence_population_pct", title="Part relative moyenne par ann√©e", hole=0.35)
    st.plotly_chart(fig3, use_container_width=True)

# =========================
# üëÄ EXPLORATEUR (Pygwalker)
# =========================
with onglets[5]:
    st.header("Explorateur visuel libre (Pygwalker)")
    st.info("Astuce : glissez-d√©posez les champs √† gauche pour cr√©er vos vues interactives.")

    # Test rapide : s'assurer que les composants HTML sont OK
    components.html("<div style='padding:8px;border:1px solid #eee;border-radius:8px'>‚úÖ Test composant HTML OK</div>", height=60)

    if donnees_nettoyees is None or donnees_nettoyees.empty:
        st.warning("Aucune donn√©e disponible √† explorer.")
    else:
        try:
            # M√©thode recommand√©e (API Streamlit de Pygwalker)
            from pygwalker.api.streamlit import init_streamlit_comm, get_streamlit_html
            init_streamlit_comm()
            pyg_html = get_streamlit_html(donnees_nettoyees, use_kernel_calc=True, spec=None)
            components.html(pyg_html, height=950, scrolling=True)
            st.success("Pygwalker (API Streamlit) charg√©.")
        except Exception as e_api:
            # Fallback g√©n√©rique (ne bloque pas la page si √©chec)
            try:
                import pygwalker as pyg
                st.info("Chargement fallback Pygwalker (m√©thode g√©n√©rique).")
                pyg_html = pyg.to_html(donnees_nettoyees)
                components.html(pyg_html, height=950, scrolling=True)
                st.success("Pygwalker (fallback) charg√©.")
            except Exception as e_fallback:
                st.error("Pygwalker n‚Äôa pas pu √™tre rendu, mais le reste de l‚Äôapplication reste disponible.")
                st.caption(f"D√©tails : {type(e_api).__name__ if e_api else ''} {e_api or e_fallback}")

# =========================
# „ÄΩÔ∏è MOD√âLISATION
# =========================
with onglets[6]:
    st.header("Mod√©lisation supervis√©e (r√©gression)")

    # Param√®tres utilisateur
    colp1, colp2, colp3 = st.columns(3)
    with colp1:
        type_modele = st.selectbox(
            "Choisir un mod√®le",
            ["R√©gression lin√©aire", "R√©gression polynomiale", "For√™t al√©atoire", "KNN r√©gression", "R√©seau de neurones (ANN)"]
        )
    with colp2:
        test_size = st.slider("Taille test (%)", 10, 40, 20, step=5)
    with colp3:
        random_state = st.number_input("Graine al√©atoire", value=42, step=1)

    # Donn√©es mod√®le sans trous (√©viter crash scikit-learn)
    df_model = donnees_nettoyees[[
        "annee", "regions_districts", "villes_communes", "maladie", "incidence_population_pct"
    ]].dropna()
    if df_model.empty:
        st.error("Impossible d'entra√Æner : aucune ligne compl√®te (X et y) apr√®s suppression des valeurs manquantes.")
        st.stop()

    X = df_model[["annee", "regions_districts", "villes_communes", "maladie"]]
    y = df_model["incidence_population_pct"]

    colonnes_numeriques = ["annee"]
    colonnes_categorielles = ["regions_districts", "villes_communes", "maladie"]

    preprocesseur = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), colonnes_numeriques),
            ("cat", OneHotEncoder(handle_unknown="ignore"), colonnes_categorielles)
        ]
    )

    # Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size/100, random_state=int(random_state)
    )

    # Pipeline mod√®le
    if type_modele == "R√©gression lin√©aire":
        modele = LinearRegression()
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    elif type_modele == "R√©gression polynomiale":
        pipeline = Pipeline([
            ("prep", preprocesseur),
            ("poly", PolynomialFeatures(degree=2, include_bias=False)),
            ("mod", LinearRegression())
        ])

    elif type_modele == "For√™t al√©atoire":
        modele = RandomForestRegressor(n_estimators=300, random_state=int(random_state))
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    elif type_modele == "KNN r√©gression":
        modele = KNeighborsRegressor(n_neighbors=7)
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    else:  # R√©seau de neurones (ANN)
        modele = MLPRegressor(hidden_layer_sizes=(128, 64), activation="relu", solver="adam",
                              max_iter=1000, random_state=int(random_state))
        pipeline = Pipeline([("prep", preprocesseur), ("mod", modele)])

    # Entra√Ænement + √âvaluation
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = root_mean_squared_error(y_test, y_pred)  # ‚úÖ plus d‚Äôavertissement squared=False

    colm1, colm2, colm3 = st.columns(3)
    colm1.metric("R¬≤", f"{r2:0.3f}")
    colm2.metric("MAE", f"{mae:0.3f}")
    colm3.metric("RMSE", f"{rmse:0.3f}")

    with st.expander("Voir la validation crois√©e (5 plis)"):
        scores = cross_val_score(pipeline, X, y, cv=5, scoring="r2")
        st.write("Scores R¬≤ par pli :", [f"{s:0.3f}" for s in scores])
        st.write("R¬≤ moyen :", f"{np.mean(scores):0.3f} ¬± {np.std(scores):0.3f}")

    # Pipeline disponible pour l‚Äôonglet Pr√©diction
    st.session_state["pipeline_modele"] = pipeline
    st.success("Mod√®le entra√Æn√© et stock√© pour l‚Äôonglet ‚óª Pr√©diction.")

# =========================
# ‚óª PR√âDICTION
# =========================
with onglets[7]:
    st.header("Pr√©dire l‚Äôincidence (%) selon vos s√©lections")

    if "pipeline_modele" not in st.session_state:
        st.warning("Veuillez d‚Äôabord entra√Æner un mod√®le dans l‚Äôonglet „ÄΩÔ∏è Mod√©lisation.")
    else:
        pipe = st.session_state["pipeline_modele"]

        if "modele_info" in st.session_state:
            st.info(st.session_state["modele_info"])

        colpr1, colpr2, colpr3, colpr4 = st.columns(4)
        with colpr1:
            annee_sel = st.selectbox("Ann√©e", sorted(donnees_nettoyees["annee"].dropna().astype(int).unique()))
        with colpr2:
            region_sel = st.selectbox("R√©gion/District", sorted(donnees_nettoyees["regions_districts"].dropna().unique()))
        with colpr3:
            ville_sel = st.selectbox("Ville/Commune", sorted(donnees_nettoyees["villes_communes"].dropna().unique()))
        with colpr4:
            maladie_sel = st.selectbox("Maladie", sorted(donnees_nettoyees["maladie"].dropna().unique()))

        saisie = pd.DataFrame({
            "annee": [int(annee_sel)],
            "regions_districts": [region_sel],
            "villes_communes": [ville_sel],
            "maladie": [maladie_sel]
        })

        if st.button("üîÆ Lancer la pr√©diction"):
            y_hat = pipe.predict(saisie)[0]
            st.success(f"Incidence attendue : **{y_hat:.2f} %**")

            cond = (
                (donnees_nettoyees["annee"] == int(annee_sel)) &
                (donnees_nettoyees["regions_districts"] == region_sel) &
                (donnees_nettoyees["villes_communes"] == ville_sel) &
                (donnees_nettoyees["maladie"] == maladie_sel)
            )
            ref_local = donnees_nettoyees.loc[cond, "incidence_population_pct"].mean()
            if not np.isnan(ref_local):
                st.info(f"Moyenne observ√©e (m√™mes filtres, historique) : **{ref_local:.2f} %**")

# =========================
# üõñ SOURCE
# =========================
with onglets[8]:
    st.header("Origine des donn√©es")
    st.markdown("""
    - **Source ouverte** : *Incidences de maladies sur la population de 2012 √† 2015*.  
    - **Lien** : https://data.gouv.ci/datasets/incidence-de-maladies-sur-la-population-de-2012-a-2015
    """)
    st.write("Utilisez les autres onglets pour naviguer dans l‚Äôanalyse, la mod√©lisation et la pr√©diction.")
